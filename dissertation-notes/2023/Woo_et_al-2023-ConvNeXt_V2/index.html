<!-- ./node_modules/hexo-theme-anzhiyu/layout/includes/layout.pug--><!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》 | Karl的博客</title><meta name="keywords" content="论文笔记,CVPR"><meta name="author" content="Karl"><meta name="copyright" content="Karl"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》"><meta name="application-name" content="论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》"><meta property="og:url" content="http://blog.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/index.html"><meta property="og:site_name" content="Karl的博客"><meta property="og:description" content="ConvNeXt V2：使用掩码自动编码器共同设计和扩展ConvNet。"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://img.karltan.com/covers/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2.png"><meta property="article:author" content="Karl"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://img.karltan.com/covers/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2.png"><meta name="description" content="ConvNeXt V2：使用掩码自动编码器共同设计和扩展ConvNet。"><link rel="shortcut icon" href="/img/logo.png"><link rel="canonical" href="http://blog.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//static.cloudflareinsights.com"/><link rel="preconnect" href="//www.clarity.ms"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="ItAgqL0bGv4TvuAzDl6nNhCuwt5RdBLYRkwae25qGzU"/><meta name="baidu-site-verification" content="codeva-Y7ehYLkADp"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@1.0.17/lib/assets/font-awesome-animation.min.css"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.20/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?0f2c96ab05c3c6d77e2d8fbf3240e404";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script defer="defer" data-pjax="data-pjax" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;758e166757ec488583caf56b7dd7f095&quot;}"></script><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "i0moouu8jj");</script><script>const GLOBAL_CONFIG = {
  linkPageTop: {"enable":true,"title":"与数百名博主无限进步","addFriendPlaceholder":"昵称（请勿包含博客等字样）：\n网站地址（要求博客地址，请勿提交个人主页）：\n头像图片url（请提供尽可能清晰的图片）：\n描述：\n站点截图（可选）：\n"},
  peoplecanvas: undefined,
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"tianli","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"a93a787ee06b121647ed","Referer":"https://blog.karltan.com/"},
  diytitle: undefined,
  LA51: {"enable":true,"ck":"3Gbf0O9t4EtAOhf1","LingQueMonitorID":"3GbfAYtZPDEan7kS"},
  greetingBox: {"enable":true,"default":"晚上好👋","list":[{"greeting":"晚安😴","startTime":0,"endTime":5},{"greeting":"早上好鸭👋, 祝你一天好心情！","startTime":6,"endTime":9},{"greeting":"上午好👋, 状态很好，鼓励一下～","startTime":10,"endTime":10},{"greeting":"11点多啦, 在坚持一下就吃饭啦～","startTime":11,"endTime":11},{"greeting":"午安👋, 宝贝","startTime":12,"endTime":13},{"greeting":"🌈充实的一天辛苦啦！","startTime":14,"endTime":17},{"greeting":"18点喽, 奖励一顿丰盛的大餐吧🍔。","startTime":18,"endTime":19},{"greeting":"晚上好👋, 在属于自己的时间好好放松😌~","startTime":20,"endTime":24}]},
  twikooEnvId: 'https://twikoo.karltan.com/.netlify/functions/twikoo',
  commentBarrageConfig:{"enable":true,"maxBarrage":1,"barrageTime":4000,"accessToken":"6f88301de4664d9d9a7cadf39a9f6e5a","mailMd5":""},
  root: '/',
  preloader: {"source":2},
  friends_vue_info: {"apiurl":"https://fcircle.karltan.com/"},
  navMusic: false,
  mainTone: undefined,
  authorStatus: {"skills":["🤖️ 数码科技爱好者","🔍 分享与热心帮助","🏠 智能家居小能手","🔨 设计开发一条龙","🤝 专修交互与设计","🏃 脚踏实地行动派","🧱 团队小组发动机","💢 壮汉人狠话不多"]},
  algolia: {"appId":"8C3UHN3LPN","apiKey":"e00dcc69cdc423d89a288bc784a14012","indexName":"blog-search","hits":{"per_page":6},"languages":{"input_placeholder":"输入关键词后按下回车查找","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: {"limitDay":1,"position":"top","messagePrev":"本文距上次修改已经","messageNext":"天，其中的内容可能已经不再适用。"},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: Karl","link":"链接: ","source":"来源: Karl的博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false,
  shortcutKey: {"enable":true,"delay":100,"shiftDelay":200},
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: 'Karl的博客',
  title: '论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》',
  postAI: 'true',
  pageFillDescription: 'ConvNeXt V2 Co-designing and Scaling ConvNets with Masked Autoencoders, Abstract, 1. Introduction, 2. Related Work, 3. Fully Convolutional Masked Autoencoder, 4. Global Response Normalization, 5. ImageNet Experiments, 6. Transfer Learning Experiments, 7. Conclusion, Appendix, A. Implementation Details, A.1. ConvNeXt V2 model configurations, A.2. ImageNet Experiments, A.3. Object detection and segmentation on COCO, A.4. Semantic segmentation in ADE20K, B. Complete comparisons with V1, C. Further Analyses, D. Additional Experiments原文链接论文笔记的博客链接论文笔记博客论文链接代码链接在改进的架构和更好的表示学习框架的推动下视觉识别领域在本世纪年代初经历了快速的现代化和性能提升例如以为代表的现代卷积神经网络已经在各种场景中展示了强大的性能虽然这些模型最初是为使用标签进行监督学习而设计的但它们也可能受益于自监督学习技术如掩码自动编码器然而我们发现简单地结合这两种方法会导致表现欠佳在本文中我们提出了一个全卷积掩码自编码器框架和一个新的全局响应归一化层该层可以添加到架构中以增强信道间特征竞争这种自监督学习技术和架构改进的共同设计产生了一个名为的新模型家族它显著提高了纯在各种识别基准上的性能包括分类检测和分割我们还提供了各种大小的预训练模型从在上具有精度的高效参数模型到仅使用公共训练数据即可实现最先进的精度的模型在前几十年研究突破的基础上视觉识别领域迎来了大规模视觉表征学习的新时代预训练的大规模视觉模型已经成为特征学习和实现广泛视觉应用的基本工具视觉表示学习系统的性能在很大程度上受三个主要因素的影响选择的神经网络架构用于训练网络的方法和用于训练的数据在视觉识别领域这些领域的进步都有助于整体性能的提高神经网络架构设计的创新一直在表征学习领域发挥着重要作用卷积神经网络架构对计算机视觉研究产生了重大影响因为它允许在各种视觉识别任务中使用通用的特征学习方法而不是依赖于人工特征工程近年来最初为自然语言处理而开发的架构也因其在模型和数据集大小方面的强大缩放行为而受到欢迎最近架构使传统的卷积网络现代化并证明纯卷积模型也可以是可扩展的架构然而探索神经网络架构设计空间的最常见方法仍然是通过对上的监督学习性能进行基准测试在另一项研究中视觉表征学习的重点已经从有标签的监督学习转向有预训练目标的自我监督预训练在许多不同的自监督算法中掩码自编码器最近将掩码语言建模成功地引入了视觉领域并迅速成为视觉表征学习的一种流行方法然而自监督学习中的一个常见做法是使用为监督学习设计的预定架构并假设该设计是固定的例如是使用视觉架构开发的将架构的设计元素和自监督学习框架结合起来是可能的但是这样做可能会在使用带有掩码自编码器的时带来挑战一个问题是有一个特定的编解码器设计该设计针对的序列处理能力进行了优化这使得计算量大的编码器能够专注于可见的小块从而减少预训练成本这种设计可能与使用密集滑动窗口的标准卷积神经网络不兼容此外如果不考虑体系结构和训练目标之间的关系那么是否能够实现最佳性能可能是不清楚的事实上之前的研究表明用基于掩码的自监督学习训练卷积神经网络可能很困难而且经验证据表明和卷积神经网络可能具有不同的特征学习行为从而影响表征质量为此我们提出在同一框架下共同设计网络架构和掩码自编码器目的是使基于掩码的自监督学习对模型有效并获得与使用相似的结果在设计掩码自编码器时我们将掩码输入视为一组稀疏小块并使用稀疏卷积只处理可见部分这个想法的灵感来自于在处理大规模点云时使用稀疏卷积在实践中我们可以用稀疏卷积实现在微调时权重被转换回标准的密集层而不需要特殊处理为了进一步提高预训练效率我们将解码器替换为单个块使整个设计完全卷积我们观察到这些变化的混合结果学习到的特征是有用的并且在基线结果上有所改进但是微调性能仍然不如基于的模型好然后我们对的不同训练配置进行特征空间分析当直接在掩码输入上训练时我们发现了层特征崩溃的潜在问题为了解决这个问题我们建议增加一个全局响应规范化层来增强通道间的特征竞争当模型用掩码自编码器预训练时这种变化是最有效的这表明重用来自监督学习的固定架构设计可能是次优的总之我们介绍了当与掩码自编码器结合使用时它展示了改进的性能我们发现该模型显著提高了纯卷积神经网络在各种下游任务上的性能包括分类对象检测和分割模型可用于各种计算机制包括不同复杂性的模型从参数的模型在上达到的精度到使用标签时达到最先进的精度的模型卷积神经网络的设计于世纪年代首次引入并使用反向传播进行训练多年来在优化准确性和效率方面经历了许多改进这些创新主要是通过在数据集上使用监督训练发现的近年来人们在使用自监督的预训练任务如旋转预测和着色来执行架构搜索方面做出了一些努力例如最近对设计空间进行了全面的回顾并证明纯可以像视觉一样具有可扩展性这已经成为许多应用中的主导架构在需要较低复杂性的场景中表现尤为出色我们的模型由自监督学习驱动提供了一种简单的方法来升级现有模型并在广泛的用例中实现性能的显著提升以掩码自编码器为代表的掩码图像建模是一种最新的自监督学习策略掩码自编码器作为一种神经网络预训练框架在视觉识别领域显示出广泛的影响然而原始的掩码自编码器由于其不对称的编解码器设计而不能直接应用于卷积神经网络替代框架如已经尝试将该方法用于卷积神经网络但结果好坏参半使用一些卷积块作为输入标记器据我们所知没有预训练的模型表明自监督学习可以提高最佳的监督结果我们的方法在概念上很简单并且以完全卷积的方式运行学习信号是通过以高掩蔽比例随机掩蔽原始输入视觉效果并让模型在给定剩余上下文的情况下预测缺失部分来生成的我们的框架如图所示现在我们将更详细地描述它的主要组件我们使用随机掩蔽策略掩蔽比例为由于卷积模型具有分层设计其中在不同阶段对特征进行下采样在最后阶段生成掩码并递归上采样以达到最佳分辨率为了在实践中实现这一点我们从原始输入图像中随机去除的块我们使用最小的数据增强只包括随机调整大小的裁剪在我们的方法中我们使用模型作为编码器使掩码图像建模有效的一个挑战是防止模型学习允许它从掩码区域复制和粘贴信息的快捷方式在基于的模型中这相对容易防止因为它可以将可见的小块作为编码器的唯一输入然而使用卷积神经网络实现这一点更加困难因为必须保留二维图像结构虽然朴素的解决方案涉及在输入端引入可学习的掩码令牌但这些方法降低了预训练的效率并导致训练和测试时间不一致因为在测试时没有掩码令牌当掩蔽比例很高时这变得特别成问题为了解决这个问题我们的新见解是从稀疏数据视角来看待被掩盖的图像这是受到任务中稀疏点云学习的启发我们的关键观察是被遮挡的图像可以表示为二维稀疏的像素数组基于这一见解将稀疏卷积合并到我们的框架中以促进掩码自编码器的预训练是很自然的在实践中在预训练过程中我们建议将编码器中的标准卷积层转换为子流形稀疏卷积使模型仅对可见数据点进行操作我们注意到稀疏卷积层可以在微调阶段转换回标准卷积而不需要额外的处理作为一种替代方法也可以在密集卷积操作之前和之后应用二进制掩蔽操作该操作在数值上与稀疏卷积具有相同的效果理论上计算强度更高但在等加速器上可能更友好我们使用轻量级的普通的块作为解码器这在整体上形成了一个不对称的编码器解码器架构因为编码器更重并且具有层次结构我们还考虑了更复杂的解码器如分层解码器或但更简单的单个块解码器在微调精度和显著减少预训练时间方面表现良好如表所示我们将解码器的尺寸设置为我们计算重建图像与目标图像之间的均方误差与类似目标是原始输入的逐块归一化图像并且损失仅应用于被掩蔽的补丁我们现在结合上述建议提出了一个全卷积掩码自动编码器为了评估该框架的有效性我们使用模型作为编码器并进行了一系列消融研究在整篇论文中我们关注端到端微调性能因为它在迁移学习中具有实际意义并使用它来评估学习表征的质量我们使用数据集分别进行次和次预训练和微调并报告单个中心裁剪的前个验证精度关于实验设置的更多细节可以在附录中找到为了理解在我们的框架中使用稀疏卷积的影响我们首先研究了它如何影响掩码图像预训练期间学习到的表示的质量我们的实证研究结果表明为了达到良好的效果防止掩码区域的信息泄露是至关重要的接下来我们将自我监督方法与监督学习方法进行比较具体来说我们获得了两个基线实验结果使用相同配方的监督基线和原始论文中提供的监督训练基线我们发现我们的预训练提供了比随机基线更好的初始化即但它仍然需要赶上在原始监督设置中获得的最佳性能这与最近使用基于的模型的掩码图像建模的成功形成对比其中预训练的模型显著优于有监督的模型这促使我们研究编码器在掩码自动编码器预训练期间面临的独特挑战我们接下来将讨论在本节中我们将介绍一种新的全局响应归一化技术以使预训练与架构相结合更加有效我们首先通过定性和定量特征分析来激励我们的方法为了更深入地了解学习行为我们首先在特征空间中进行定性分析我们可视化了预训练的模型的激活并注意到一个有趣的特征崩溃现象有许多死的或饱和的特征图并且激活在通道之间变得冗余我们在图中展示了一些可视化效果这种行为主要在块的维度扩展层中观察到为了进一步定量验证我们的观察结果我们进行了特征余弦距离分析给定一个激活张量是第个通道的特征图我们将其重塑为维向量并通过计算通道上的平均成对余弦距离距离值越高表示特征越多样距离值越低表示特征冗余为了进行分析我们从验证集中随机选择张不同类别的图像并从不同模型的每一层提取高维特征包括模型监督模型和预训练的模型然后我们计算每个图像的每层距离并将所有图像的值平均结果如图所示预训练的模型显示出明显的特征崩溃趋势这与我们从之前的激活可视化中观察到的结果一致这促使我们在学习过程中考虑如何使特征多样化防止特征崩溃大脑中有许多促进神经元多样性的机制例如侧抑制可以帮助增强激活神经元的反应增加单个神经元对刺激的对比和选择性同时也增加了神经元群体反应的多样性在深度学习中这种形式的横向抑制可以通过响应归一化来实现在这项工作中我们引入了一个新的响应归一化层称为全局响应归一化旨在增加通道的对比度和选择性给定输入特征本文提出的单元包括三个步骤全局特征聚合特征归一化特征校准首先我们将空间特征映射聚合为具有全局函数的向量这可以看作是一个简单的池化层我们在表中实验了不同的函数有趣的是广泛使用的特征聚合器在我们的案例中表现不佳相反我们发现使用基于范数的特征聚合特别是使用范数会产生更好的性能这为我们提供了一组聚合值其中是聚合第个通道统计信息的标量接下来我们对聚合值应用响应归一化函数具体来说我们使用标准的分裂归一化如下其中是第通道的范数为了考虑更深层中通道数量的增加在实践中我们还通过通道计数缩放规范化值直观地对于第个通道计算其相对于所有其他通道的相对重要性与其他形式的归一化类似这一步通过相互抑制在渠道之间产生特征竞争在表中我们还研究了其他归一化函数的使用发现简单的分裂归一化效果最好尽管标准化在应用于相同的范数聚合值时产生类似的结果最后我们使用计算的特征归一化分数校准原始输入响应核心单元非常容易实现只需要三行代码并且没有可学习的参数单元的伪码在算法中为了简化优化我们添加了两个额外的可学习参数和并将它们初始化为零我们还在层的输入和输出之间添加了残差连接最终得到的块为这种设置允许层最初执行恒等函数并在训练期间逐渐适应残差连接的重要性如表所示我们将层合并到原始的块中如图所示我们通过经验发现当应用时变得不必要并且可以删除使用这种新的模块设计我们创建了具有不同效率和容量的各种模型我们将其称为模型家族这些模型的范围从轻量级例如到计算密集型例如详细的模型配置可以在附录中找到我们现在使用框架对进行预训练并评估的影响从图的可视化和图的余弦距离分析中我们可以观察到有效地缓解了特征折叠问题余弦距离值一直很高表明特征多样性在各层之间保持不变这种行为类似于预训练的模型总的来说这表明的学习行为可以类似于在类似的掩码图像预训练框架下接下来我们评估微调性能当配备时预训练模型可以显著优于监督模型通过增强特征多样性来提高表征质量这在模型中是不存在的但事实证明对于基于掩码的预训练至关重要注意这种改进是在不增加额外的参数开销或增加的情况下实现的附加的仿射参数可以忽略不计其他归一化层的表现是否与全局响应归一化层一样好在表中我们将与三种广泛使用的归一化层进行了比较局部响应归一化批归一化和层归一化我们观察到只有可以显著优于监督基线缺乏全局上下文因为它仅对比附近通道沿批量轴进行空间归一化这不适合屏蔽输入通过全局均值和方差标准化隐式鼓励特征竞争但效果不如另一种增强神经元间竞争的方法是使用动态特征门控方法在表中我们将与两个经典的门控层进行了比较和侧重于通道门控而侧重于空间门控这两个模块都可以增加单个通道的对比度类似于的功能更简单更有效因为它不需要额外的参数层如最后我们研究了在预训练和微调中的重要性我们在表中给出了结果其中我们从微调中删除或者仅在微调时添加新初始化的无论哪种方式我们都观察到显著的性能下降这表明在预训练和微调中保持是重要的在本节中我们提出并分析了两个关键的建议预训练框架和架构它们被共同设计以使基于掩码的自监督预训练成功我们展示了这些设计协同良好并为将模型缩放到各种尺寸提供了坚实的基础此外我们通过实验将我们的方法与以前的掩码图像建模方法进行了比较不仅如此我们展示了我们最大的模型使用框架进行预训练并在数据集上进行微调可以在数据集上实现的精度仅使用公开可用的数据在本文中我们进行了一项独特的研究包括共同设计自监督学习框架和模型架构改进层通过实证研究他们的学习行为表中的结果表明了这种方法的重要性我们发现在不修改模型架构的情况下使用框架对表示学习质量的影响有限同样在监督设置下新的层对性能的影响相当小然而两者的结合会显著改善微调性能这支持了模型和学习框架应该一起考虑的观点特别是当涉及到自我监督学习时在本研究中我们评估了种不同尺寸的模型从低容量模型到高容量模型我们使用提出的框架对这些模型进行预训练并将微调结果与完全监督的模型进行比较结果如图所示展示了强大的模型缩放行为在所有模型大小的监督基线上始终如一地提高了性能这是第一次在如此广泛的模型范围内证明掩码图像建模的好处无论是在有效性还是效率方面完整的表格结果可在附录中找到我们将我们的方法与之前的掩码自编码器方法进行了比较这些方法都是为基于的模型设计的结果总结在表中我们的框架在所有模型尺寸上都优于用预训练的与使用预训练的普通相比尽管使用的参数少得多但我们的方法在大型模型体系中的表现相似然而在庞大的模型体系中我们的方法略显落后这可能是因为一个巨大的模型可以从自我监督的预训练中获益更多正如我们接下来将看到的这个差距可以通过额外的中间微调来缩小我们还展示了中间微调结果训练过程包括三个步骤预训练微调微调我们使用分辨率的图像进行预训练和微调我们将我们的结果与最先进的架构设计进行了比较包括基于卷积的基于的和混合设计所有这些结果都使用监督标签进行训练结果总结在表中我们的方法使用基于卷积的架构仅使用公开可用的数据即和达到了新的最先进的精度我们现在对迁移学习性能进行基准测试首先我们评估共同设计的影响即比较与我们还直接将我们的方法与预训练的模型进行了比较训练和测试的细节在附录中提供我们在数据集上微调并在数据集上报告检测和分割结果如表所示随着我们的建议得到实施我们看到情况在逐步改善从到新引入了层增强了性能在此基础上当从监督学习过渡到基于的自监督学习时模型进一步受益于更好的初始化当两者同时应用时可以获得最佳性能此外我们的最终提案在上预训练的在所有模型尺寸上都优于在巨大的模型范围内实现了最大的差距综上所述我们使用框架对语义分割任务进行了实验我们的结果显示出与目标检测实验相似的趋势并且我们的最终模型比监督的对应模型显著改进它在和模型系统中的性能也与相当但在大型模型系统中优于在本文中我们介绍了一个新的模型家族称为它涵盖了更广泛的复杂性虽然体系结构的变化很小但它是专门为更适合自监督学习而设计的使用我们的全卷积掩码自动编码器进行预训练我们可以显著提高纯卷积神经网络在各种下游任务中的性能包括分类对象检测和分割本附录提供了实现细节包括模型配置预训练和微调配方以及预训练的稀疏和密集编码方法参见在中我们在和上对和进行了完整的微调精度比较在中我们使用类选择性指数对稀疏编码和一般特征分析的效率进行了分析最后在中我们对掩蔽比和成分分析进行了额外的消融研究我们还比较了掩码图像建模和对比学习基本模型即和遵循与相同的和通道设置配置给定上述相同的定义我们缩放模型以提供广泛的模型大小范围针对多种场景首先为了得到有效的模型我们按如下比例缩小分别表示和模型最初设计于接下来为了引入大容量的变体我们按以下方式进行扩展为本文新提出的模型所有模型共享相同的预训练设置如表所示我们使用线性缩放规则由于学习能力因模型大小而异我们对每个模型采用不同的微调配方我们将它们总结在表和中我们看到更长的微调周期有助于小模型在这项工作中我们采用了两种不同的学习率层衰减策略我们将三个连续的层视为单个层并对它们使用相同的衰减值我们为每层分配不同的值两者都遵循标准衰减规则默认是策略但是我们将策略应用于和模型我们使用预训练的模型进行中间微调我们使用和模型表和表总结了这些设置类似地对于小模型使用更大的学习率衰减值是有帮助的我们提出了两种可能的实现来实现预训练使用外部库支持的稀疏卷积进行稀疏编码用掩码密集卷积模拟稀疏编码通过在标准卷积操作前后分别应用二进制掩码可以很容易地实现由于它们产生数字上相同的输出因此可以根据不同的用例采用两者在这项工作中我们在环境下采用稀疏编码其中我们使用库和框架我们使用在加速器上使用基于密集掩码转换的编码主论文中的实验都是在上进行的但是我们发布了一个的复制对于实验我们使用工具箱和预训练的最终模型权重作为网络初始化所有模型都以倍的时间表个和为进行训练我们使用一个优化器其学习率为权值衰减为扫描层学习率衰减为随机深度率衰减为我们采用大规模抖动增强分辨率尺度范围我们在推理期间使用进行单尺度测试对于实验我们使用工具箱我们使用具有以下超参数的优化器权重衰减为为衰减率为学习率为随机深度率所有模型都训练了次迭代输入分辨率为在推理中使用的分辨率为的多尺度检验与类似我们在上进行监督微调后使用模型权值初始化分割模型因为我们发现它的性能优于直接使用自监督预训练权值在表和表中我们详细介绍了和之间的实验水平比较特别是表显示了使用八个模型的微调结果和范围从低计算到大容量模型我们在所有模型中都看到了一致和显著的改进当结构从升级到并使用自监督学习框架时性能达到最佳证明了协同设计的有效性在表中我们给出了中间微调结果预训练和微调过程包括三个步骤预训练微调微调在这里我们专注于五种模型和相比版本我们看到了持续的改进特别是和模型的性能优于的下一级模型尺寸即和模型模型也实现了一个新的最先进的性能为我们的建议表明纯卷积模型也可以通过基于掩码的预训练成为强大的可扩展的视觉学习器我们的框架的关键设计选择之一是在预训练期间使用稀疏卷积其主要目的是阻断来自掩码区域的信息流方便掩码自编码器的预训练作为副产品它还在预训练期间提供了改进的计算和内存效率因为内核仅适用于可见像素然而我们注意到稀疏卷积库并没有针对现代硬件进行高度优化并且实现的效率通常取决于实践中使用的框架为了更好地理解使用稀疏卷积实现的实际预训练效率我们使用和进行了基准测试我们模拟了预训练掩码输入图像大小掩码比掩码大小并比较了基于稀疏卷积和基于密集掩码卷积编码器之间的训练吞吐量图像和最大内存使用量虽然结果可能因实验环境而有所不同我们使用和但我们观察到预训练效率适度增加吞吐量平均增加倍最大内存使用量减少倍随着模型尺寸的增加这种差距变得更加明显预训练的与相比具有鲜明的特征特征为了理解这一点我们对和的预训练权值进行了类选择性指数分析类选择指数是衡量最高类条件平均活动与所有其他类条件平均活动之间差异的度量标准最终的规范化值介于和之间表示过滤器仅对单个类激活表示过滤器对所有类统一激活在图中我们使用每个残差块的输出绘制了模型中所有中间层的类选择性指数分布前期和的分布紧密匹配但在较深层如第阶段第层开始出现发散随着层的加深该图显示双峰倾向于包含比单峰更多的类通用特征由于与类无关的特性更具可移植性这将在下游任务中带来更好的微调性能我们将更多的探索留给未来的研究提出的全局关系网络包括三个步骤全局特征聚合特征归一化特征校准本文主要论证了基于范数的聚合和分裂归一化的结合在实践中效果良好表使用作为编码器验证了这些组件的各自贡献当任何一个组件被丢弃时性能都会显著下降并且如果在特征归一化之前没有进行全局聚合训练将变得不稳定这支持了这两种操作协同工作以使有效的想法我们对掩码尺寸为的掩模比进行了超参数分析如图所示结果表明掩蔽比在到范围内会产生最好的结果掩蔽比为可以提供最高的性能在这项工作中我们比较了两种主流的自监督学习方法的性能对比学习和掩码图像建模具体来说我们比较了的端到端微调性能是目前最先进的对比学习方法与我们提出的框架使用相同的作为编码器我们遵循每种方法的默认预训练和微调配方并给出如下结果我们使用的监督学习基线作为参考上表表明的表示质量优于并且优于监督基线这与最近的观察结果一致即在端到端微调方面掩膜图像建模比基于对比学习的提供了更好的结果在这项工作中纯卷积神经网络也使这一成功成为可能',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-04-04 20:00:00',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/mycss.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.0.0"><link rel="alternate" href="/atom.xml" title="Karl的博客" type="application/atom+xml">
<link rel="alternate" href="/rss2.xml" title="Karl的博客" type="application/rss+xml">
</head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" href="https://blog.karltan.com/" title="Karl的博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/logo.png" alt="Karl的博客"/><span class="back-menu-item-text">Karl的博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://www.karltan.com/" title="Karl的导航"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://www.karltan.com/favicon.ico" alt="Karl的导航"/><span class="back-menu-item-text">Karl的导航</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">博客分流</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://v.karltan.com/" title="Vercel"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://assets.vercel.com/image/upload/front/favicon/vercel/favicon.ico" alt="Vercel"/><span class="back-menu-item-text">Vercel</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://c.karltan.com/" title="Cloudflare"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://dash.cloudflare.com/favicon-32x32.png" alt="Cloudflare"/><span class="back-menu-item-text">Cloudflare</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">工具</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://npmzjk.karltan.com/" title="NPM"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npmzjk.karltan.com/images/favicons/favicon-32x32.png" alt="NPM"/><span class="back-menu-item-text">NPM</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://paste.karltan.com/" title="Free-Bin"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://paste.karltan.com/static/favicon.ico" alt="Free-Bin"/><span class="back-menu-item-text">Free-Bin</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://tools.karltan.com/" title="IT-TOOLS"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://tools.karltan.com/android-chrome-192x192.png" alt="IT-TOOLS"/><span class="back-menu-item-text">IT-TOOLS</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://memos.karltan.com/" title="Memos"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://memos.karltan.com/logo.png" alt="Memos"/><span class="back-menu-item-text">Memos</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://wbo.karltan.com/" title="WBO"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://wbo.karltan.com/favicon.ico" alt="WBO"/><span class="back-menu-item-text">WBO</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://git.karltan.com/" title="Gitea"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://git.karltan.com/assets/img/logo.svg" alt="Gitea"/><span class="back-menu-item-text">Gitea</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">Karl的博客</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives"><i class="fa-solid fa-box-archive faa-tada"></i><span> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories"><i class="fa-solid fa-palette faa-tada"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags"><i class="fa-solid fa-tags faa-tada"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link"><i class="fa-solid fa-link faa-tada"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle"><i class="fa-brands fa-artstation faa-tada"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments"><i class="fa-solid fa-comments faa-tada"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/essay"><i class="fa-solid fa-comment-dots faa-tada"></i><span> 说说</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/music"><i class="fa-solid fa-music faa-tada"></i><span> 音乐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album"><i class="fa-solid fa-images faa-tada"></i><span> 相册</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://status.karltan.com/status/1"><i class="fa-solid fa-chart-line faa-tada"></i><span> 网站监控</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="fa-solid fa-shoe-prints faa-tada"></i><span> 随便逛逛</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/about"><i class="fa-solid fa-heart faa-tada"></i><span> 关于我</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button only-home" id="travellings_button" title="随机前往一个开往项目网站"><a class="site-page" onclick="anzhiyu.totraveling()" title="随机前往一个开往项目网站" href="javascript:void(0);" rel="external nofollow" data-pjax-state="external"><i class="anzhiyufont anzhiyu-icon-train"></i></a></div><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" alt="微信" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/wechat.jpg"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" alt="支付宝" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/alipay.jpg"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/AcWing/" style="font-size: 1.05rem;">AcWing<sup>33</sup></a><a href="/tags/CUDA/" style="font-size: 1.05rem;">CUDA<sup>1</sup></a><a href="/tags/CVPR/" style="font-size: 1.05rem;">CVPR<sup>3</sup></a><a href="/tags/ICLR/" style="font-size: 1.05rem;">ICLR<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 1.05rem;">Linux<sup>1</sup></a><a href="/tags/MAPL/" style="font-size: 1.05rem;">MAPL<sup>1</sup></a><a href="/tags/MySQL/" style="font-size: 1.05rem;">MySQL<sup>1</sup></a><a href="/tags/NIPS/" style="font-size: 1.05rem;">NIPS<sup>1</sup></a><a href="/tags/PyTorch/" style="font-size: 1.05rem;">PyTorch<sup>1</sup></a><a href="/tags/Python/" style="font-size: 1.05rem;">Python<sup>1</sup></a><a href="/tags/RSS/" style="font-size: 1.05rem;">RSS<sup>1</sup></a><a href="/tags/Ubuntu/" style="font-size: 1.05rem;">Ubuntu<sup>3</sup></a><a href="/tags/Windows/" style="font-size: 1.05rem;">Windows<sup>1</sup></a><a href="/tags/arXiv/" style="font-size: 1.05rem;">arXiv<sup>1</sup></a><a href="/tags/mAP/" style="font-size: 1.05rem;">mAP<sup>1</sup></a><a href="/tags/tmux/" style="font-size: 1.05rem;">tmux<sup>1</sup></a><a href="/tags/vim/" style="font-size: 1.05rem;">vim<sup>1</sup></a><a href="/tags/%E4%BB%A3%E7%A0%81/" style="font-size: 1.05rem;">代码<sup>1</sup></a><a href="/tags/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/" style="font-size: 1.05rem;">位姿估计<sup>1</sup></a><a href="/tags/%E6%89%A9%E5%AE%B9/" style="font-size: 1.05rem;">扩容<sup>1</sup></a><a href="/tags/%E6%95%B0%E5%AD%A6/" style="font-size: 1.05rem;">数学<sup>1</sup></a><a href="/tags/%E6%97%8B%E8%BD%AC%E8%A1%A8%E7%A4%BA/" style="font-size: 1.05rem;">旋转表示<sup>1</sup></a><a href="/tags/%E6%9D%8E%E6%B2%90/" style="font-size: 1.05rem;">李沐<sup>76</sup></a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 1.05rem;">深度学习<sup>79</sup></a><a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 1.05rem;">目标检测<sup>1</sup></a><a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 1.05rem;">笔记<sup>77</sup></a><a href="/tags/%E7%AE%97%E6%B3%95%E9%A2%98/" style="font-size: 1.05rem;">算法题<sup>33</sup></a><a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" style="font-size: 1.05rem;">论文笔记<sup>9</sup></a><a href="/tags/%E9%98%BF%E9%87%8C%E4%BA%91/" style="font-size: 1.05rem;">阿里云<sup>1</sup></a><a href="/tags/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/" style="font-size: 1.05rem;">高等数学<sup>1</sup></a><a href="/tags/%E9%AD%94%E6%B3%95/" style="font-size: 1.05rem;">魔法<sup>1</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="anzhiyufont anzhiyu-icon-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">2024年04月</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">2024年03月</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/02/"><span class="card-archive-list-date">2024年02月</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/01/"><span class="card-archive-list-date">2024年01月</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">10</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/12/"><span class="card-archive-list-date">2023年12月</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">48</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/11/"><span class="card-archive-list-date">2023年11月</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">7</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">2023年10月</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">32</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">2023年09月</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">6</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item on" id="consoleCommentBarrage" onclick="anzhiyu.switchCommentBarrage()" title="热评开关"><a class="commentBarrage"><i class="anzhiyufont anzhiyu-icon-message"></i></a></div><div class="console-btn-item" id="consoleKeyboard" onclick="anzhiyu.keyboardToggle()" title="快捷键开关"><a class="keyboard-switch"><i class="anzhiyufont anzhiyu-icon-keyboard"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url">论文笔记</a><i class="anzhiyufont anzhiyu-icon-angle-right post-meta-separator"></i><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/2023/" itemprop="url">2023</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>论文笔记</span></a><a class="article-meta__tags" href="/tags/CVPR/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>CVPR</span></a></span></div></div><h1 class="post-title" itemprop="name headline">论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2024-04-04T05:00:00.000Z" title="发表于 2024-04-04 13:00:00">2024-04-04</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2024-04-04T12:00:00.000Z" title="更新于 2024-04-04 20:00:00">2024-04-04</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">9.7k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>32分钟</span></span><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为长沙"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>长沙</span><span class="post-meta-separator"></span><span class="post-meta-commentcount"><i class="anzhiyufont anzhiyu-icon-comments post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/#post-comment" tabindex="-1"><span id="twikoo-count"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></a></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://img.karltan.com/covers/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2.png"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><div class="post-ai-description"><div class="ai-title"><i class="anzhiyufont anzhiyu-icon-bilibili"></i><div class="ai-title-text">AI-摘要</div><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right"></i><i class="anzhiyufont anzhiyu-icon-circle-dot" title="朗读摘要"></i><div id="ai-tag">Tianli GPT</div></div><div class="ai-explanation">AI初始化中...</div><div class="ai-btn-box"><div class="ai-btn-item">介绍自己 🙈</div><div class="ai-btn-item">生成本文简介 👋</div><div class="ai-btn-item">推荐相关文章 📖</div><div class="ai-btn-item">前往主页 🏠</div><div class="ai-btn-item" id="go-tianli-blog">前往爱发电购买</div></div><script data-pjax src="/js/anzhiyu/ai_abstract.js"></script></div><article class="post-content" id="article-container" itemscope itemtype="http://blog.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/"><header><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url">论文笔记</a><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/2023/" itemprop="url">2023</a><a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" tabindex="-1" itemprop="url">论文笔记</a><a href="/tags/CVPR/" tabindex="-1" itemprop="url">CVPR</a><h1 id="CrawlerTitle" itemprop="name headline">论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">Karl</span><time itemprop="dateCreated datePublished" datetime="2024-04-04T05:00:00.000Z" title="发表于 2024-04-04 13:00:00">2024-04-04</time><time itemprop="dateCreated datePublished" datetime="2024-04-04T12:00:00.000Z" title="更新于 2024-04-04 20:00:00">2024-04-04</time></header><h1 id="ConvNeXt-V2-Co-designing-and-Scaling-ConvNets-with-Masked-Autoencoders"><a href="#ConvNeXt-V2-Co-designing-and-Scaling-ConvNets-with-Masked-Autoencoders" class="headerlink" title="ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders"></a>ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders</h1><p>原文链接：<a href="https://blog.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/">论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》 | Karl的博客</a></p>
<p>CSDN链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/karltan0328/article/details/137381266">论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》-CSDN博客</a></p>
<p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2301.00808">[2301.00808] ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders (arxiv.org)</a></p>
<p>代码链接：<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/ConvNeXt-V2">facebookresearch/ConvNeXt-V2: Code release for ConvNeXt V2 model (github.com)</a></p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>在改进的架构和更好的表示学习框架的推动下，视觉识别领域在本世纪20年代初经历了快速的现代化和性能提升。例如，以ConvNeXt[52]为代表的现代卷积神经网络已经在各种场景中展示了强大的性能。虽然这些模型最初是为使用ImageNet标签进行监督学习而设计的，但它们也可能受益于自监督学习技术，如掩码自动编码器（MAE）[31]。然而，我们发现简单地结合这两种方法会导致表现欠佳。在本文中，我们提出了一个全卷积掩码自编码器框架和一个新的全局响应归一化（GRN）层，该层可以添加到ConvNeXt架构中以增强信道间特征竞争。这种自监督学习技术和架构改进的共同设计产生了一个名为ConvNeXt V2的新模型家族，它显著提高了纯ConvNets在各种识别基准上的性能，包括ImageNet分类、COCO检测和ADE20K分割。我们还提供了各种大小的预训练ConvNeXt V2模型，从在ImageNet上具有76.7% top-1精度的高效3.7 M参数Atto模型，到仅使用公共训练数据即可实现最先进的88.9%精度的650M Huge模型。</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>在前几十年研究突破的基础上[34, 44, 47, 60, 68]，视觉识别领域迎来了大规模视觉表征学习的新时代。预训练的大规模视觉模型已经成为特征学习和实现广泛视觉应用的基本工具。视觉表示学习系统的性能在很大程度上受三个主要因素的影响：选择的神经网络架构、用于训练网络的方法和用于训练的数据。在视觉识别领域，这些领域的进步都有助于整体性能的提高。</p>
<p>神经网络架构设计的创新一直在表征学习领域发挥着重要作用。卷积神经网络架构（ConvNets）[34, 44, 47]对计算机视觉研究产生了重大影响，因为它允许在各种视觉识别任务中使用通用的特征学习方法[25, 33]，而不是依赖于人工特征工程。近年来，最初为自然语言处理而开发的transformer架构[68]也因其在模型和数据集大小方面的强大缩放行为[21]而受到欢迎。最近，ConvNeXt[52]架构使传统的卷积网络现代化，并证明纯卷积模型也可以是可扩展的架构。然而，探索神经网络架构设计空间的最常见方法仍然是通过对ImageNet上的监督学习性能进行基准测试。</p>
<p>在另一项研究中，视觉表征学习的重点已经从有标签的监督学习转向有预训练目标的自我监督预训练。在许多不同的自监督算法中，掩码自编码器（mask autoencoders, MAE）[31]最近将掩码语言建模成功地引入了视觉领域，并迅速成为视觉表征学习的一种流行方法。然而，自监督学习中的一个常见做法是使用为监督学习设计的预定架构，并假设该设计是固定的。例如，MAE是使用视觉transformer[21]架构开发的。</p>
<p>将架构的设计元素和自监督学习框架结合起来是可能的，但是这样做可能会在使用带有掩码自编码器的ConvNeXt时带来挑战。一个问题是，MAE有一个特定的编解码器设计，该设计针对transformers的序列处理能力进行了优化，这使得计算量大的编码器能够专注于可见的小块，从而减少预训练成本。这种设计可能与使用密集滑动窗口的标准卷积神经网络不兼容。此外，如果不考虑体系结构和训练目标之间的关系，那么是否能够实现最佳性能可能是不清楚的。事实上，之前的研究表明，用基于掩码的自监督学习训练卷积神经网络可能很困难，而且经验证据表明，transformers和卷积神经网络可能具有不同的特征学习行为，从而影响表征质量。</p>
<p>为此，我们提出在同一框架下共同设计网络架构和掩码自编码器，目的是使基于掩码的自监督学习对ConvNeXt模型有效，并获得与使用transformers相似的结果。</p>
<p>在设计掩码自编码器时，我们将掩码输入视为一组稀疏小块，并使用稀疏卷积[28]只处理可见部分。这个想法的灵感来自于在处理大规模3D点云时使用稀疏卷积[15, 76]。在实践中，我们可以用稀疏卷积实现ConvNeXt，在微调时，权重被转换回标准的密集层，而不需要特殊处理。为了进一步提高预训练效率，我们将transformer解码器替换为单个ConvNeXt块，使整个设计完全卷积。我们观察到这些变化的混合结果：学习到的特征是有用的，并且在基线结果上有所改进，但是微调性能仍然不如基于transformer的模型好。</p>
<p>然后，我们对ConvNeXt的不同训练配置进行特征空间分析。当直接在掩码输入上训练ConvNeXt时，我们发现了MLP层特征崩溃的潜在问题。为了解决这个问题，我们建议增加一个全局响应规范化层来增强通道间的特征竞争。当模型用掩码自编码器预训练时，这种变化是最有效的，这表明重用来自监督学习的固定架构设计可能是次优的。</p>
<p>总之，我们介绍了ConvNeXt V2，当与掩码自编码器结合使用时，它展示了改进的性能。我们发现，该模型显著提高了纯卷积神经网络在各种下游任务上的性能，包括ImageNet分类[60]、COCO对象检测[49]和ADE20K分割[81]。ConvNeXt V2模型可用于各种计算机制，包括不同复杂性的模型：从3.7M参数的Atto模型，在ImageNet上达到76.7%的top-1精度，到使用IN-22K标签时达到最先进的88.9%精度的650M Huge模型。</p>
<h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h2><p><strong>ConvNets.</strong> 卷积神经网络的设计于20世纪80年代首次引入，并使用反向传播进行训练，多年来在优化、准确性和效率方面经历了许多改进[35, 36, 39, 44, 58, 61, 63, 75]。这些创新主要是通过在ImageNet数据集上使用监督训练发现的。近年来，人们在使用自监督的预训练任务（如旋转预测和着色）来执行架构搜索方面做出了一些努力，例如UnNAS[50]。最近，ConvNeXt[52]对设计空间进行了全面的回顾，并证明纯ConvNets可以像视觉transformers一样具有可扩展性[21, 51]，这已经成为许多应用中的主导架构。ConvNeXt在需要较低复杂性的场景中表现尤为出色[7, 70, 71]。我们的ConvNeXt V2模型由自监督学习驱动，提供了一种简单的方法来升级现有模型，并在广泛的用例中实现性能的显著提升。</p>
<p><strong>Masked Autoencoders.</strong> 以掩码自编码器[31]为代表的掩码图像建模是一种最新的自监督学习策略。掩码自编码器作为一种神经网络预训练框架，在视觉识别领域显示出广泛的影响。然而，原始的掩码自编码器由于其不对称的编解码器设计而不能直接应用于卷积神经网络。替代框架，如[3, 77]已经尝试将该方法用于卷积神经网络，但结果好坏参半。MCMAE[23]使用一些卷积块作为输入标记器。据我们所知，没有预训练的模型表明自监督学习可以提高最佳的ConvNeXt监督结果。</p>
<h2 id="3-Fully-Convolutional-Masked-Autoencoder"><a href="#3-Fully-Convolutional-Masked-Autoencoder" class="headerlink" title="3. Fully Convolutional Masked Autoencoder"></a>3. Fully Convolutional Masked Autoencoder</h2><p>我们的方法在概念上很简单，并且以完全卷积的方式运行。学习信号是通过以高掩蔽比例随机掩蔽原始输入视觉效果并让模型在给定剩余上下文的情况下预测缺失部分来生成的。我们的框架如图2所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404145621488.png" alt="image-20240404145621488"></p>
<p>现在我们将更详细地描述它的主要组件。</p>
<p><strong>Masking.</strong> 我们使用随机掩蔽策略，掩蔽比例为0.6。由于卷积模型具有分层设计，其中在不同阶段对特征进行下采样，在最后阶段生成掩码并递归上采样以达到最佳分辨率。为了在实践中实现这一点，我们从原始输入图像中随机去除60%的$32 \times 32$块。我们使用最小的数据增强，只包括随机调整大小的裁剪。</p>
<p><strong>Encoder design.</strong> 在我们的方法中，我们使用ConvNeXt[52]模型作为编码器。使掩码图像建模有效的一个挑战是防止模型学习允许它从掩码区域复制和粘贴信息的快捷方式。在基于transformer的模型中，这相对容易防止，因为它可以将可见的小块作为编码器的唯一输入。然而，使用卷积神经网络实现这一点更加困难，因为必须保留二维图像结构。虽然朴素的解决方案涉及在输入端引入可学习的掩码令牌[3, 77]，但这些方法降低了预训练的效率，并导致训练和测试时间不一致，因为在测试时没有掩码令牌。当掩蔽比例很高时，这变得特别成问题。</p>
<p>为了解决这个问题，我们的新见解是从“稀疏数据视角”来看待被掩盖的图像，这是受到3D任务中稀疏点云学习的启发[15, 76]。我们的关键观察是，被遮挡的图像可以表示为二维稀疏的像素数组。基于这一见解，将稀疏卷积合并到我们的框架中以促进掩码自编码器的预训练是很自然的。在实践中，在预训练过程中，我们建议将编码器中的标准卷积层转换为子流形稀疏卷积，使模型仅对可见数据点进行操作[15, 27, 28]。我们注意到稀疏卷积层可以在微调阶段转换回标准卷积，而不需要额外的处理。作为一种替代方法，也可以在密集卷积操作之前和之后应用二进制掩蔽操作。该操作在数值上与稀疏卷积具有相同的效果，理论上计算强度更高，但在TPU等AI加速器上可能更友好。</p>
<p><strong>Decoder design.</strong> 我们使用轻量级的、普通的ConvNeXt块作为解码器。这在整体上形成了一个不对称的编码器-解码器架构，因为编码器更重并且具有层次结构。我们还考虑了更复杂的解码器，如分层解码器[48, 59]或transformers[21, 31]，但更简单的单个ConvNeXt块解码器在微调精度和显著减少预训练时间方面表现良好，如表1所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404151132387.png" alt="image-20240404151132387"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404151211498.png" alt="image-20240404151211498"></p>
<p>我们将解码器的尺寸设置为512。</p>
<p><strong>Reconstruction target.</strong> 我们计算重建图像与目标图像之间的均方误差（MSE）。与MAE[31]类似，目标是原始输入的逐块归一化图像，并且损失仅应用于被掩蔽的补丁。</p>
<p><strong>FCMAE.</strong> 我们现在结合上述建议提出了一个全卷积掩码自动编码器（FCMAE）。为了评估该框架的有效性，我们使用ConvNeXt-Base模型作为编码器，并进行了一系列消融研究。在整篇论文中，我们关注端到端微调性能，因为它在迁移学习中具有实际意义，并使用它来评估学习表征的质量。</p>
<p>我们使用ImageNet-1K（IN-1K）数据集分别进行800次和100次预训练和微调，并报告单个$224 \times 224$中心裁剪的前1个IN-1K验证精度。关于实验设置的更多细节可以在附录中找到。</p>
<p>为了理解在我们的FCMAE框架中使用稀疏卷积的影响，我们首先研究了它如何影响掩码图像预训练期间学习到的表示的质量。我们的实证研究结果表明，为了达到良好的效果，防止掩码区域的信息泄露是至关重要的。</p>
<p>接下来，我们将自我监督方法与监督学习方法进行比较。具体来说，我们获得了两个基线实验结果：使用相同配方的监督100 epoch基线和原始ConvNeXt论文[52]中提供的300 epoch监督训练基线。我们发现我们的FCMAE预训练提供了比随机基线更好的初始化（即$82.7 \to 83.7$），但它仍然需要赶上在原始监督设置中获得的最佳性能。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404152152273.png" alt="image-20240404152152273"></p>
<p>这与最近使用基于transformer的模型的掩码图像建模的成功形成对比[3, 31, 77]，其中预训练的模型显著优于有监督的模型。这促使我们研究ConvNeXt编码器在掩码自动编码器预训练期间面临的独特挑战，我们接下来将讨论。</p>
<h2 id="4-Global-Response-Normalization"><a href="#4-Global-Response-Normalization" class="headerlink" title="4. Global Response Normalization"></a>4. Global Response Normalization</h2><p>在本节中，我们将介绍一种新的全局响应归一化（GRN）技术，以使FCMAE预训练与ConvNeXt架构相结合更加有效。我们首先通过定性和定量特征分析来激励我们的方法。</p>
<p><strong>Feature collapse.</strong> 为了更深入地了解学习行为，我们首先在特征空间中进行定性分析。我们可视化了FCMAE预训练的ConvNeXt-Base模型的激活，并注意到一个有趣的“特征崩溃”现象：有许多死的或饱和的特征图，并且激活在通道之间变得冗余。我们在图3中展示了一些可视化效果：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404152752530.png" alt="image-20240404152752530"></p>
<p>这种行为主要在ConvNeXt块[52]的维度扩展MLP层中观察到。</p>
<p><strong>Feature cosine distance analysis.</strong> 为了进一步定量验证我们的观察结果，我们进行了特征余弦距离分析。给定一个激活张量$X \in R^{H \times W \times C}$，$X_i \in R^{H \times W}$是第$i$个通道的特征图。我们将其重塑为$HW$维向量，并通过$\frac{1}{C^2}\sum_i^C\sum_j^C\frac{1 - \cos(X_i, X_h)}{2}$计算通道上的平均成对余弦距离。距离值越高表示特征越多样，距离值越低表示特征冗余。</p>
<p>为了进行分析，我们从ImageNet-1K验证集中随机选择1000张不同类别的图像，并从不同模型的每一层提取高维特征，包括FCMAE模型、ConvNeXt监督模型[52]和MAE预训练的ViT模型[31]。然后，我们计算每个图像的每层距离，并将所有图像的值平均。结果如图4所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404153255459.png" alt="image-20240404153255459"></p>
<p>FCMAE预训练的ConvNeXt模型显示出明显的特征崩溃趋势，这与我们从之前的激活可视化中观察到的结果一致。这促使我们在学习过程中考虑如何使特征多样化，防止特征崩溃。</p>
<p><strong>Approach.</strong> 大脑中有许多促进神经元多样性的机制。例如，侧抑制[6, 30]可以帮助增强激活神经元的反应，增加单个神经元对刺激的对比和选择性，同时也增加了神经元群体反应的多样性。在深度学习中，这种形式的横向抑制可以通过响应归一化[45]来实现。在这项工作中，我们引入了一个新的响应归一化层，称为全局响应归一化（GRN），旨在增加通道的对比度和选择性。给定输入特征$X \in R^{H \times W \times C}$，本文提出的GRN单元包括三个步骤：</p>
<ol>
<li>全局特征聚合；</li>
<li>特征归一化；</li>
<li>特征校准。</li>
</ol>
<p>首先，我们将空间特征映射$X_i$聚合为具有全局函数$\mathcal{G}(\cdot)$的向量$gx$：</p>
<script type="math/tex; mode=display">
\mathcal{G}(X) := X \in \mathcal{R}^{H \times W \times C} \to gx \in \mathcal{R}^C</script><p>这可以看作是一个简单的池化层。我们在表2a中实验了不同的函数：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404154320071.png" alt="image-20240404154320071"></p>
<p>有趣的是，广泛使用的特征聚合器global average pooling[37, 72]在我们的案例中表现不佳。相反，我们发现使用基于范数的特征聚合，特别是使用L2范数，会产生更好的性能。这为我们提供了一组聚合值$\mathcal{G}(X) = gx = \{\Vert X_1 \Vert, \Vert X_2 \Vert, \cdots, \Vert X_C \Vert\} \in \mathcal{R}^C$，其中$\mathcal{G}(X)_i = \Vert X_i \Vert$是聚合第$i$个通道统计信息的标量。</p>
<p>接下来，我们对聚合值应用响应归一化函数$\mathcal{N}(\cdot)$。具体来说，我们使用标准的分裂归一化如下：</p>
<script type="math/tex; mode=display">
\mathcal{N}(\Vert X_i \Vert) := \Vert X_i \Vert \in \mathcal{R} \to \frac{\Vert X_i \Vert}{\sum_{j = 1, 2, \cdots, C} \Vert X_j \Vert} \in \mathcal{R}</script><p>其中$\Vert X_i \Vert$是第$i$通道的L2范数（为了考虑更深层中通道数量的增加，在实践中，我们还通过通道计数$C$缩放规范化值）。直观地，对于第$i$个通道，$\mathcal{N}(\Vert X_i \Vert) := \Vert X_i \Vert \in \mathcal{R} \to \frac{\Vert X_i \Vert}{\sum_{j = 1, 2, \cdots, C} \Vert X_j \Vert} \in \mathcal{R}$计算其相对于所有其他通道的相对重要性。与其他形式的归一化类似[42, 45, 68]，这一步通过相互抑制在渠道之间产生特征竞争。在表2b中，我们还研究了其他归一化函数的使用：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404154320071.png" alt="image-20240404154320071"></p>
<p>发现简单的分裂归一化效果最好，尽管标准化$\frac{\Vert X_i \Vert - \mu}{\sigma}$在应用于相同的L2范数聚合值时产生类似的结果。</p>
<p>最后，我们使用计算的特征归一化分数校准原始输入响应：</p>
<script type="math/tex; mode=display">
X_i = X_i * \mathcal{N}(\mathcal{G}(X)_i) \in \mathcal{R}^{H \times W}</script><p>核心GRN单元非常容易实现，只需要三行代码，并且没有可学习的参数。GRN单元的伪码在算法1中：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404155317540.png" alt="image-20240404155317540"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># gamma, beta: learnable affine transform parameters</span></span><br><span class="line"><span class="comment"># X: input of shape (N, H, W, C)</span></span><br><span class="line"></span><br><span class="line">gx = torch.norm(X, p=<span class="number">2</span>, dim=(<span class="number">1</span>,<span class="number">2</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">nx = gx / (gx.mean(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>) + <span class="number">1e-6</span>)</span><br><span class="line"><span class="keyword">return</span> gamma * (X * nx) + beta + X</span><br></pre></td></tr></table></figure>
<p>为了简化优化，我们添加了两个额外的可学习参数，$\gamma$和$\beta$，并将它们初始化为零。我们还在GRN层的输入和输出之间添加了残差连接。最终得到的GRN块为$X_i = \gamma <em> X_i </em> \mathcal{N}(\mathcal{G}(X)_i) + \beta + X_i$。这种设置允许GRN层最初执行恒等函数，并在训练期间逐渐适应。残差连接的重要性如表2c所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404154320071.png" alt="image-20240404154320071"></p>
<p><strong>ConvNeXt V2.</strong> 我们将GRN层合并到原始的ConvNeXt块中，如图5所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404155853899.png" alt="image-20240404155853899"></p>
<p>我们通过经验发现，当应用GRN时，LayerScale[65]变得不必要，并且可以删除。使用这种新的模块设计，我们创建了具有不同效率和容量的各种模型，我们将其称为ConvNeXt V2模型家族。这些模型的范围从轻量级（例如Atto[70]）到计算密集型（例如Huge）。详细的模型配置可以在附录中找到。</p>
<p><strong>Impact of GRN.</strong> 我们现在使用FCMAE框架对ConvNeXt V2进行预训练，并评估GRN的影响。从图3的可视化和图4的余弦距离分析中，我们可以观察到ConvNeXt V2有效地缓解了特征折叠问题。余弦距离值一直很高，表明特征多样性在各层之间保持不变。这种行为类似于MAE预训练的ViT模型[31]。总的来说，这表明ConvNeXt V2的学习行为可以类似于ViT，在类似的掩码图像预训练框架下。</p>
<p>接下来，我们评估微调性能。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404160212348.png" alt="image-20240404160212348"></p>
<p>当配备GRN时，FCMAE预训练模型可以显著优于300 epoch监督模型。GRN通过增强特征多样性来提高表征质量，这在V1模型中是不存在的，但事实证明对于基于掩码的预训练至关重要。注意，这种改进是在不增加额外的参数开销或增加FLOPS的情况下实现的（附加的仿射参数$\frac{\gamma}{\beta}$可以忽略不计）。</p>
<p><strong>Relation to feature normalization methods.</strong> 其他归一化层[2, 41, 45, 67, 73]的表现是否与全局响应归一化（GRN）层一样好？在表2d中：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404154320071.png" alt="image-20240404154320071"></p>
<p>我们将GRN与三种广泛使用的归一化层进行了比较：局部响应归一化（LRN）[45]，批归一化（BN）[41]和层归一化（LN）[2]。我们观察到只有GRN可以显著优于监督基线。LRN缺乏全局上下文，因为它仅对比附近通道。BN沿批量轴进行空间归一化，这不适合屏蔽输入。LN通过全局均值和方差标准化隐式鼓励特征竞争，但效果不如GRN。</p>
<p><strong>Relation to feature gating methods.</strong> 另一种增强神经元间竞争的方法是使用动态特征门控方法[37, 56, 69, 72, 78]。在表2e中：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404154320071.png" alt="image-20240404154320071"></p>
<p>我们将GRN与两个经典的门控层进行了比较：squeeze-and-excite（SE）[37]和convolutional block attention module（CBAM）[72]。SE侧重于通道门控，而CBAM侧重于空间门控。这两个模块都可以增加单个通道的对比度，类似于GRN的功能。GRN更简单、更有效，因为它不需要额外的参数层（如MLP）。</p>
<p><strong>The role of GRN in pre-training/fine-tuning.</strong> 最后，我们研究了GRN在预训练和微调中的重要性。我们在表2f中给出了结果：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404154320071.png" alt="image-20240404154320071"></p>
<p>其中我们从微调中删除GRN，或者仅在微调时添加新初始化的GRN。无论哪种方式，我们都观察到显著的性能下降，这表明在预训练和微调中保持GRN是重要的。</p>
<h2 id="5-ImageNet-Experiments"><a href="#5-ImageNet-Experiments" class="headerlink" title="5. ImageNet Experiments"></a>5. ImageNet Experiments</h2><p>在本节中，我们提出并分析了两个关键的建议，FCMAE预训练框架和ConvNeXt V2架构，它们被共同设计以使基于掩码的自监督预训练成功。我们展示了这些设计协同良好，并为将模型缩放到各种尺寸提供了坚实的基础。此外，我们通过实验将我们的方法与以前的掩码图像建模方法进行了比较。不仅如此，我们展示了我们最大的ConvNeXt V2 Huge模型，使用FCMAE框架进行预训练并在ImageNet-22K数据集上进行微调，可以在ImageNet-1K数据集上实现88.9%的top-1精度，仅使用公开可用的数据。</p>
<p><strong>Co-design matters.</strong> 在本文中，我们进行了一项独特的研究，包括共同设计自监督学习框架（FCMAE）和模型架构改进（GRN层），通过实证研究他们的学习行为。表3中的结果表明了这种方法的重要性：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404170509595.png" alt="image-20240404170509595"></p>
<p>我们发现，在不修改模型架构的情况下使用FCMAE框架对表示学习质量的影响有限。同样，在监督设置下，新的GRN层对性能的影响相当小。然而，两者的结合会显著改善微调性能。这支持了模型和学习框架应该一起考虑的观点，特别是当涉及到自我监督学习时。</p>
<p><strong>Model scaling.</strong> 在本研究中，我们评估了8种不同尺寸的模型，从低容量3.7M Atto模型到高容量650M Huge模型。我们使用提出的FCMAE框架对这些模型进行预训练，并将微调结果与完全监督的模型进行比较。</p>
<p>结果如图1所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404170927174.png" alt="image-20240404170927174"></p>
<p>展示了强大的模型缩放行为，在所有模型大小的监督基线上始终如一地提高了性能。这是第一次在如此广泛的模型范围内证明掩码图像建模的好处，无论是在有效性还是效率方面。完整的表格结果可在附录中找到。</p>
<p><strong>Comparisons with previous methods.</strong> 我们将我们的方法与之前的掩码自编码器方法[3, 31, 77]进行了比较，这些方法都是为基于transformer的模型设计的。结果总结在表4中：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404171108800.png" alt="image-20240404171108800"></p>
<p>我们的框架在所有模型尺寸上都优于用SimMIM[77]预训练的Swintransformer。与使用MAE[31]预训练的普通ViT相比，尽管使用的参数少得多(198M vs 307M)，但我们的方法在大型模型体系中的表现相似。然而，在庞大的模型体系中，我们的方法略显落后。这可能是因为一个巨大的ViT模型可以从自我监督的预训练中获益更多。正如我们接下来将看到的，这个差距可以通过额外的中间微调来缩小。</p>
<p><strong>ImageNet-22K intermediate fine-tuning.</strong> 我们还展示了ImageNet-22K中间微调结果[3]。训练过程包括三个步骤：</p>
<ol>
<li>FCMAE预训练；</li>
<li>ImageNet-22K微调；</li>
<li>ImageNet-1K微调。</li>
</ol>
<p>我们使用$384 \times 384$分辨率的图像进行预训练和微调[38]。我们将我们的结果与最先进的架构设计进行了比较，包括基于卷积的[52, 64]，基于transformer的[22]和混合设计[20, 66]。所有这些结果都使用ImageNet-22K监督标签进行训练。结果总结在表5中：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404171500940.png" alt="image-20240404171500940"></p>
<p>我们的方法使用基于卷积的架构，仅使用公开可用的数据（即ImageNet-1K和ImageNet-22K）达到了新的最先进的精度。</p>
<h2 id="6-Transfer-Learning-Experiments"><a href="#6-Transfer-Learning-Experiments" class="headerlink" title="6. Transfer Learning Experiments"></a>6. Transfer Learning Experiments</h2><p>我们现在对迁移学习性能进行基准测试。首先，我们评估共同设计的影响，即比较ConvNeXt V1 + supervised与ConvNeXt V2 + FCMAE。我们还直接将我们的方法与SimMIM预训练的Swintransformer模型进行了比较[77]。训练和测试的细节在附录中提供。</p>
<p><strong>Object detection and segmentation on COCO.</strong> 我们在COCO数据集[49]上微调Mask R-CNN[33]，并在COCO val2017数据集上报告检测$\text{mAP}^\text{box}$和分割$\text{mAP}^\text{mask}$。结果如表6所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404172848277.png" alt="image-20240404172848277"></p>
<p>随着我们的建议得到实施，我们看到情况在逐步改善。从V1到V2，新引入了GRN层，增强了性能。在此基础上，当从监督学习过渡到基于FCMAE的自监督学习时，模型进一步受益于更好的初始化。当两者同时应用时，可以获得最佳性能。此外，我们的最终提案，在FCMAE上预训练的ConvNeXt V2，在所有模型尺寸上都优于Swintransformer，在巨大的模型范围内实现了最大的差距。</p>
<p><strong>Semantic segmentation on ADE20K.</strong> 综上所述，我们使用UperNet框架[74]对ADE20K[82]语义分割任务进行了实验。我们的结果显示出与目标检测实验相似的趋势，并且我们的最终模型比V1监督的对应模型显著改进。它在base和large模型系统中的性能也与Swintransformer相当，但在大型模型系统中优于Swin。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404190657722.png" alt="image-20240404190657722"></p>
<h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><p>在本文中，我们介绍了一个新的ConvNet模型家族，称为ConvNeXt V2，它涵盖了更广泛的复杂性。虽然体系结构的变化很小，但它是专门为更适合自监督学习而设计的。使用我们的全卷积掩码自动编码器进行预训练，我们可以显著提高纯卷积神经网络在各种下游任务中的性能，包括ImageNet分类、COCO对象检测和ADE20K分割。</p>
<h2 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h2><p>本附录提供了实现细节，包括模型配置，预训练和微调配方，以及FCMAE预训练的稀疏和密集编码方法（参见$\S$A）。在$\S$B中，我们在ImageNet 1K和22K上对ConvNeXt V1和V2进行了完整的微调精度比较。在$\S$C中，我们使用类选择性指数对稀疏编码和一般特征分析的效率进行了分析。最后，在$\S$D中，我们对掩蔽比和GRN成分分析进行了额外的消融研究。我们还比较了FCMAE（掩码图像建模）和MoCo V3（对比学习）。</p>
<h3 id="A-Implementation-Details"><a href="#A-Implementation-Details" class="headerlink" title="A. Implementation Details"></a>A. Implementation Details</h3><h4 id="A-1-ConvNeXt-V2-model-configurations"><a href="#A-1-ConvNeXt-V2-model-configurations" class="headerlink" title="A.1. ConvNeXt V2 model configurations"></a>A.1. ConvNeXt V2 model configurations</h4><p>基本模型，即Tiny（28M）， Base（89M）和Large（198M），遵循与ConvNeXt V1[52]相同的stage、block（B）和通道（C）设置配置。</p>
<ul>
<li>ConvNeXt V2-T: C = 96, B = (3, 3, 9, 3)</li>
<li>ConvNeXt V2-B: C = 128, B = (3, 3, 27, 3)</li>
<li>ConvNeXt V2-L: C = 192, B = (3, 3, 27, 3)</li>
</ul>
<p>给定上述相同的定义，我们缩放模型以提供广泛的模型大小范围，针对多种场景。首先，为了得到有效的模型，我们按如下比例缩小：</p>
<ul>
<li>ConvNeXt V2-A: C = 40, B = (2, 2, 6, 2)</li>
<li>ConvNeXt V2-F: C = 48, B = (2, 2, 6, 2)</li>
<li>ConvNeXt V2-P: C = 64, B = (2, 2, 6, 2)</li>
<li>ConvNeXt V2-N: C = 80, B = (2, 2, 8, 2)</li>
</ul>
<p>A、F、P、N分别表示Atto（3.7M）、Femto（5.2M）、Pico（9.1M）和Nano（15.6M）模型，最初设计于[70]。接下来，为了引入大容量的变体，我们按以下方式进行扩展：</p>
<ul>
<li>ConvNeXt V2-H: C = 352, B = (3, 3, 27, 3)</li>
</ul>
<p>H为本文新提出的Huge（659M）模型。</p>
<h4 id="A-2-ImageNet-Experiments"><a href="#A-2-ImageNet-Experiments" class="headerlink" title="A.2. ImageNet Experiments"></a>A.2. ImageNet Experiments</h4><p><strong>Pre-training.</strong> 所有模型共享相同的预训练设置，如表8所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404191554554.png" alt="image-20240404191554554"></p>
<p>我们使用线性$lr$缩放规则[26]：$lr = \frac{base_lr \times \text{batchsize}}{256}$。</p>
<p><strong>ImageNet-1K fine-tuning.</strong> 由于学习能力因模型大小而异，我们对每个模型采用不同的微调配方。我们将它们总结在表9、10和11中：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404191829977.png" alt="image-20240404191829977"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404191847071.png" alt="image-20240404191847071"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404191907357.png" alt="image-20240404191907357"></p>
<p>我们看到更长的微调周期有助于小模型。在这项工作中，我们采用了两种不同的学习率层衰减策略：</p>
<ol>
<li>group-wise[52]，我们将三个连续的层视为单个“层”，并对它们使用相同的衰减值；</li>
<li>layer-wise[3]，我们为每层分配不同的值，两者都遵循标准衰减规则。</li>
</ol>
<p>默认是layer-wise策略，但是我们将group-wise策略应用于Base和Large模型。</p>
<p><strong>ImageNet-22K intermediate fine-tuning.</strong> 我们使用FCMAE预训练的ConvNeXt模型进行ImageNet-22K中间微调。我们使用nano，tiny，base，large和huge模型。表12和表13总结了这些设置：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404191930499.png" alt="image-20240404191930499"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404191945731.png" alt="image-20240404191945731"></p>
<p>类似地，对于小模型使用更大的layer-wise学习率衰减值是有帮助的。</p>
<p><strong>Sparse encoding implementations.</strong> 我们提出了两种可能的实现来实现FCMAE预训练：</p>
<ol>
<li>使用外部库支持的稀疏卷积[15, 27, 28]进行稀疏编码[15, 18]；</li>
<li>用掩码密集卷积模拟稀疏编码，通过在标准卷积操作前后分别应用二进制掩码可以很容易地实现。</li>
</ol>
<p>由于它们产生数字上相同的输出，因此可以根据不同的用例采用两者。在这项工作中，我们在GPU环境下采用稀疏编码，其中我们使用MinkowskiEngine库[15]和PyTorch框架[57]；我们使用Jax[5]在TPU加速器上使用基于密集掩码转换的编码。主论文中的实验都是在TPU（v3-256）pods上进行的，但是我们发布了一个PyTorch的复制。</p>
<h4 id="A-3-Object-detection-and-segmentation-on-COCO"><a href="#A-3-Object-detection-and-segmentation-on-COCO" class="headerlink" title="A.3. Object detection and segmentation on COCO"></a>A.3. Object detection and segmentation on COCO</h4><p>对于COCO实验，我们使用MMDetection[10]工具箱和ImageNet-1K预训练的最终模型权重作为网络初始化。所有模型都以3倍的时间表（36个epoch）和batch size为<code>32</code>进行训练。我们使用一个AdamW优化器[54]，其学习率为<code>1e-4</code>，权值衰减为<code>0.05</code>，扫描层学习率衰减为$\{0.9, 0.95\}$，随机深度率衰减为$\{0.2, 0.3, 0.4, 0.5\}$。我们采用大规模抖动增强[24]（$1024 \times 1024$分辨率，尺度范围$[0.1, 2.0]$）。我们在推理期间使用soft-NMS[4]进行单尺度测试。</p>
<h4 id="A-4-Semantic-segmentation-in-ADE20K"><a href="#A-4-Semantic-segmentation-in-ADE20K" class="headerlink" title="A.4. Semantic segmentation in ADE20K"></a>A.4. Semantic segmentation in ADE20K</h4><p>对于ADE20K实验，我们使用MMSegmentation[17]工具箱。我们使用具有以下超参数的AdamW优化器[54]：权重衰减为<code>0.05</code>，batch size为<code>16</code>，layer-wise衰减率为$\{0.8, 0.9\}$，学习率为$\{1\text{e-}4, 2\text{e-}4, 3\text{e-}4\}$，随机深度率$\{0.1, 0.2, 0.3, 0.4\}$。所有模型都训练了160K次迭代，输入分辨率为$512 \times 512$。在推理中，使用$512 \times 2048$的分辨率为$[0.75, 0.875, 1.0, 1.125, 1.25]$的多尺度检验。</p>
<p>与[77]类似，我们在ImageNet-1K上进行监督微调后使用模型权值初始化分割模型，因为我们发现它的性能优于直接使用自监督预训练权值。</p>
<h3 id="B-Complete-comparisons-with-V1"><a href="#B-Complete-comparisons-with-V1" class="headerlink" title="B. Complete comparisons with V1"></a>B. Complete comparisons with V1</h3><p>在表14和表15中，我们详细介绍了ConvNeXt V1[52, 70]和V2之间的实验水平比较：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404193157266.png" alt="image-20240404193157266"></p>
<p>特别是，表14显示了使用八个模型的ImageNet-1K微调结果：Atto、Femto、Nano、Pico、Tiny、Base、Large和Huge，范围从低计算（Atto，3.7M）到大容量模型（Huge，660M）。我们在所有模型中都看到了一致和显著的改进。当结构从V1升级到V2并使用自监督学习框架FCMAE时，性能达到最佳，证明了协同设计的有效性。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404193233745.png" alt="image-20240404193233745"></p>
<p>在表15中，我们给出了ImageNet-22K中间微调结果。预训练和微调过程包括三个步骤：</p>
<ol>
<li>FCMAE预训练；</li>
<li>ImageNet-22K微调；</li>
<li>ImageNet-1K微调。</li>
</ol>
<p>在这里，我们专注于五种V2模型：Nano、Tiny、Base、Large和Huge。相比V1版本，我们看到了持续的改进。特别是，V2 Base（86.8%/87.7%）和Large（87.3%/88.2%）模型的性能优于V1的下一级模型尺寸，即Large（86.6%/87.5%）和XLarge（87.0%/87.8%）模型。V2 Huge模型也实现了一个新的最先进的性能为88.9%。我们的建议表明，纯卷积模型也可以通过基于掩码的预训练成为强大的、可扩展的视觉学习器。</p>
<h3 id="C-Further-Analyses"><a href="#C-Further-Analyses" class="headerlink" title="C. Further Analyses"></a>C. Further Analyses</h3><p><strong>Sparse encoding efficiency.</strong> 我们的FCMAE框架的关键设计选择之一是在预训练期间使用稀疏卷积[15, 27, 28]。其主要目的是阻断来自掩码区域的信息流，方便掩码自编码器的预训练。作为副产品，它还在预训练期间提供了改进的计算和内存效率，因为内核仅适用于可见像素。然而，我们注意到稀疏卷积库[15, 18]并没有针对现代硬件进行高度优化，并且实现的效率通常取决于实践中使用的框架[1, 5, 57]。</p>
<p>为了更好地理解使用稀疏卷积实现的实际预训练效率，我们使用Minkowski Engine v0.5.4[15]和PyTorch[57]进行了基准测试。我们模拟了预训练掩码输入（图像大小$224 \times 224$，掩码比<code>0.6</code>，掩码大小$32 \times 32$），并比较了基于稀疏卷积和基于密集掩码卷积编码器之间的训练吞吐量（图像/s）和最大GPU内存使用量（G）。虽然结果可能因实验环境而有所不同（我们使用PyTorch V1.8.0，CUDA 11.1，CuDNN 8.2和NVIDIA RTX A6000 GPU），但我们观察到预训练效率适度增加，吞吐量平均增加1.3倍，最大内存使用量减少2倍。随着模型尺寸的增加，这种差距变得更加明显。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404193902909.png" alt="image-20240404193902909"></p>
<p><strong>Class Selectivity Index.</strong> FCMAE预训练的ConvNeXt V2与V1相比具有鲜明的特征特征。为了理解这一点，我们对ConvNeXt V1和V2的FCMAE预训练权值进行了类选择性指数分析。类选择指数是衡量最高类条件平均活动与所有其他类条件平均活动之间差异的度量标准。最终的规范化值介于0和1之间，1表示过滤器仅对单个类激活，0表示过滤器对所有类统一激活。在图7中，我们使用每个残差块的输出绘制了模型中所有中间层的类选择性指数分布：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404194014921.png" alt="image-20240404194014921"></p>
<p>前期V1和V2的分布紧密匹配，但在较深层，如第3阶段第12层开始出现发散。随着层的加深，该图显示V2（双峰）倾向于包含比V1（单峰）更多的类通用特征。由于与类无关的特性更具可移植性，这将在下游任务中带来更好的微调性能。我们将更多的探索留给未来的研究。</p>
<h3 id="D-Additional-Experiments"><a href="#D-Additional-Experiments" class="headerlink" title="D. Additional Experiments"></a>D. Additional Experiments</h3><p><strong>GRN component analysis.</strong> 提出的全局关系网络（GRN）包括三个步骤：</p>
<ol>
<li>全局特征聚合；</li>
<li>特征归一化；</li>
<li>特征校准。</li>
</ol>
<p>本文主要论证了基于L2范数的聚合和分裂归一化的结合在实践中效果良好。表16使用ConvNeXt V2-Base作为编码器验证了这些组件的各自贡献：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404194210952.png" alt="image-20240404194210952"></p>
<p>当任何一个组件被丢弃时，性能都会显著下降，并且如果在特征归一化之前没有进行全局聚合，训练将变得不稳定。这支持了这两种操作协同工作以使GRN有效的想法。</p>
<p><strong>Masking ratios.</strong> 我们对掩码尺寸为$32 \times 32$的掩模比进行了超参数分析。如图8所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404194329282.png" alt="image-20240404194329282"></p>
<p>结果表明，掩蔽比在<code>0.5</code>到<code>0.7</code>范围内会产生最好的结果，掩蔽比为<code>0.6</code>可以提供最高的性能。</p>
<p><strong>Comparison with contrastive SSL.</strong> 在这项工作中，我们比较了两种主流的自监督学习（SSL）方法的性能：对比学习[8, 9, 12, 13, 14, 29, 32]和掩码图像建模[3, 31, 77]。具体来说，我们比较了MoCoV3[14]的端到端微调性能，MoCoV3[14]是目前最先进的对比学习方法，与我们提出的FCMAE框架使用相同的ConvNeXt V2-Base作为编码器。我们遵循每种方法的默认预训练和微调配方，并给出如下结果。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/image-20240404194537499.png" alt="image-20240404194537499"></p>
<p>我们使用300 epoch的监督学习基线作为参考。上表表明，FCMAE的表示质量优于MoCo V3，并且优于监督基线。这与最近的观察结果一致，即在端到端微调方面，掩膜图像建模比基于对比学习的SSL提供了更好的结果。在这项工作中，纯卷积神经网络也使这一成功成为可能。</p>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/profile.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/profile.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">Karl</div><div class="post-copyright__author_desc">日拱一卒，功不唐捐</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="http://blog.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('http://blog.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/')">论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://blog.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》&amp;url=http://blog.karltan.com/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/&amp;pic=https://img.karltan.com/covers/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2.png" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://blog.karltan.com" target="_blank">Karl的博客</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__category-list"><a class="post-meta__box__categoryes" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="categoryes-punctuation"> <i class="anzhiyufont anzhiyu-icon-inbox"></i></span>论文笔记<span class="categoryesPageCount">9</span></a><a class="post-meta__box__categoryes" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/2023/"><span class="categoryes-punctuation"> <i class="anzhiyufont anzhiyu-icon-inbox"></i></span>2023<span class="categoryesPageCount">3</span></a></div><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>论文笔记<span class="tagsPageCount">9</span></a><a class="post-meta__box__tags" href="/tags/CVPR/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>CVPR<span class="tagsPageCount">3</span></a></div></div><div class="post_share"><div class="social-share" data-image="https://img.karltan.com/covers/dissertation-notes/2021/Dosovitskiy_et_al-2021-An_Image_is_Worth_16x16_Words.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/dissertation-notes/2023/Nguyen_et_al-2023-NOPE/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/2023/Nguyen_et_al-2023-NOPE.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">论文笔记《NOPE：Novel Object Pose Estimation from a Single Image》</div></div></a></div><div class="next-post pull-right"><a href="/dissertation-notes/2021/Dosovitskiy_et_al-2021-An_Image_is_Worth_16x16_Words/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/2021/Dosovitskiy_et_al-2021-An_Image_is_Worth_16x16_Words.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">论文笔记《AN IMAGE IS WORTH 16X16 WORDS：TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE》</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/dissertation-notes/2019/Wang_et_al-2019-Normalized_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_and_Size_Estimation/" title="论文笔记《Normalized Object Coordinate Space for Category-Level 6D Object Pose and Size Estimation》"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/2019/Wang_et_al-2019-Normalized_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_and_Size_Estimation.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-10-25</div><div class="title">论文笔记《Normalized Object Coordinate Space for Category-Level 6D Object Pose and Size Estimation》</div></div></a></div><div><a href="/dissertation-notes/2023/Nguyen_et_al-2023-NOPE/" title="论文笔记《NOPE：Novel Object Pose Estimation from a Single Image》"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/2023/Nguyen_et_al-2023-NOPE.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-03-28</div><div class="title">论文笔记《NOPE：Novel Object Pose Estimation from a Single Image》</div></div></a></div><div><a href="/dissertation-notes/dissertation-summary/" title="论文总结"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/dissertation-summary.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-10-28</div><div class="title">论文总结</div></div></a></div><div><a href="/dissertation-notes/2017/Vaswani_et_al-2017-Attention_is_all_you_need/" title="论文笔记《Attention Is All You Need》"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/2017/Vaswani_et_al-2017-Attention_is_all_you_need.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-02-09</div><div class="title">论文笔记《Attention Is All You Need》</div></div></a></div><div><a href="/dissertation-notes/2018/Xiang_et_al-2018-PoseCNN/" title="论文笔记《PoseCNN：A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes》"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/2018/Xiang_et_al-2018-PoseCNN.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-10-19</div><div class="title">论文笔记《PoseCNN：A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes》</div></div></a></div><div><a href="/dissertation-notes/2019/Tillet_et_al-2019-Triton/" title="论文笔记《Triton：An Intermediate Language and Compiler for Tiled Neural Network Computations》"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/2019/Tillet_et_al-2019-Triton.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-12-26</div><div class="title">论文笔记《Triton：An Intermediate Language and Compiler for Tiled Neural Network Computations》</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div><div class="comment-tips" id="comment-tips"><span>✅ 你无需删除空行，直接评论以获取最佳展示效果</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/profile.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/chuoyichuo.gif" alt="status"/></div></div><div class="author-info__description"><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">直博狗一枚，日常会在博客上分享自己的学习笔记，希望可以帮到你。</div><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">相信你可以在这里找到对你有用的<b style="color:#fff">知识</b>和<b style="color:#fff">教程</b>。</div></div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">Karl</h1><div class="author-info__desc">日拱一卒，功不唐捐</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/karltan0328" target="_blank" title="Github"><i class="fa-brands fa-github faa-tada"></i></a><a class="social-icon faa-parent animated-hover" href="mailto:admin@karltan.com" target="_blank" title="Email"><i class="fa-solid fa-envelope faa-tada"></i></a></div></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来看我的博客鸭~</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#ConvNeXt-V2-Co-designing-and-Scaling-ConvNets-with-Masked-Autoencoders"><span class="toc-text">ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Introduction"><span class="toc-text">1. Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Related-Work"><span class="toc-text">2. Related Work</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Fully-Convolutional-Masked-Autoencoder"><span class="toc-text">3. Fully Convolutional Masked Autoencoder</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Global-Response-Normalization"><span class="toc-text">4. Global Response Normalization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-ImageNet-Experiments"><span class="toc-text">5. ImageNet Experiments</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Transfer-Learning-Experiments"><span class="toc-text">6. Transfer Learning Experiments</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Conclusion"><span class="toc-text">7. Conclusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Appendix"><span class="toc-text">Appendix</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-Implementation-Details"><span class="toc-text">A. Implementation Details</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#A-1-ConvNeXt-V2-model-configurations"><span class="toc-text">A.1. ConvNeXt V2 model configurations</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#A-2-ImageNet-Experiments"><span class="toc-text">A.2. ImageNet Experiments</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#A-3-Object-detection-and-segmentation-on-COCO"><span class="toc-text">A.3. Object detection and segmentation on COCO</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#A-4-Semantic-segmentation-in-ADE20K"><span class="toc-text">A.4. Semantic segmentation in ADE20K</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-Complete-comparisons-with-V1"><span class="toc-text">B. Complete comparisons with V1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#C-Further-Analyses"><span class="toc-text">C. Further Analyses</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#D-Additional-Experiments"><span class="toc-text">D. Additional Experiments</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/dissertation-notes/2021/Dosovitskiy_et_al-2021-An_Image_is_Worth_16x16_Words/" title="论文笔记《AN IMAGE IS WORTH 16X16 WORDS：TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE》"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/2021/Dosovitskiy_et_al-2021-An_Image_is_Worth_16x16_Words.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文笔记《AN IMAGE IS WORTH 16X16 WORDS：TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE》"/></a><div class="content"><a class="title" href="/dissertation-notes/2021/Dosovitskiy_et_al-2021-An_Image_is_Worth_16x16_Words/" title="论文笔记《AN IMAGE IS WORTH 16X16 WORDS：TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE》">论文笔记《AN IMAGE IS WORTH 16X16 WORDS：TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE》</a><time datetime="2024-04-15T07:00:00.000Z" title="发表于 2024-04-15 15:00:00">2024-04-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/" title="论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》"/></a><div class="content"><a class="title" href="/dissertation-notes/2023/Woo_et_al-2023-ConvNeXt_V2/" title="论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》">论文笔记《ConvNeXt V2：Co-designing and Scaling ConvNets with Masked Autoencoders》</a><time datetime="2024-04-04T05:00:00.000Z" title="发表于 2024-04-04 13:00:00">2024-04-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/dissertation-notes/2023/Nguyen_et_al-2023-NOPE/" title="论文笔记《NOPE：Novel Object Pose Estimation from a Single Image》"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/2023/Nguyen_et_al-2023-NOPE.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文笔记《NOPE：Novel Object Pose Estimation from a Single Image》"/></a><div class="content"><a class="title" href="/dissertation-notes/2023/Nguyen_et_al-2023-NOPE/" title="论文笔记《NOPE：Novel Object Pose Estimation from a Single Image》">论文笔记《NOPE：Novel Object Pose Estimation from a Single Image》</a><time datetime="2024-03-28T04:00:00.000Z" title="发表于 2024-03-28 12:00:00">2024-03-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/dissertation-notes/2017/Vaswani_et_al-2017-Attention_is_all_you_need/" title="论文笔记《Attention Is All You Need》"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/dissertation-notes/2017/Vaswani_et_al-2017-Attention_is_all_you_need.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文笔记《Attention Is All You Need》"/></a><div class="content"><a class="title" href="/dissertation-notes/2017/Vaswani_et_al-2017-Attention_is_all_you_need/" title="论文笔记《Attention Is All You Need》">论文笔记《Attention Is All You Need》</a><time datetime="2024-02-09T02:00:00.000Z" title="发表于 2024-02-09 10:00:00">2024-02-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/ac-diary/acwing/autumn-daily-question-2023/acwing5199/" title="AcWing 5199. 现代艺术"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.karltan.com/covers/ac-diary/acwing/autumn-daily-question-2023.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AcWing 5199. 现代艺术"/></a><div class="content"><a class="title" href="/ac-diary/acwing/autumn-daily-question-2023/acwing5199/" title="AcWing 5199. 现代艺术">AcWing 5199. 现代艺术</a><time datetime="2024-01-18T08:00:00.000Z" title="发表于 2024-01-18 16:00:00">2024-01-18</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="footer_deal"><a class="deal_link" href="mailto:admin@karltan.com" title="email"><i class="fa-solid fa-envelope"></i></a><a class="deal_link" href="/atom.xml" title="RSS"><i class="fa-solid fa-rss"></i></a><img class="footer_mini_logo" title="返回顶部" alt="返回顶部" onclick="anzhiyu.scrollToDest(0, 500)" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/profile.jpg" size="50px"/><a class="deal_link" target="_blank" rel="noopener" href="https://github.com/karltan0328" title="Github"><i class="fa-brands fa-github"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://blog.csdn.net/karltan0328" title="CSDN"><i class="fa-solid fa-c"></i></a></div><div id="workboard"><img class="workSituationImg boardsign" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/label/work_img.svg" alt="paper快来，idea快来，我要毕业🥹" title="paper快来，idea快来，我要毕业🥹"/><div id="runtimeTextTip"></div></div><div id="anzhiyu-footer"><div class="footer-group"><div class="footer-title">服务</div><div class="footer-links"><a class="footer-item" title="51la统计" target="_blank" rel="noopener" href="https://v6.51.la/">51la统计</a><a class="footer-item" title="十年之约" target="_blank" rel="noopener" href="https://www.foreverblog.cn/">十年之约</a><a class="footer-item" title="开往" target="_blank" rel="noopener" href="https://github.com/travellings-link/travellings">开往</a></div></div><div class="footer-group"><div class="footer-title">主题</div><div class="footer-links"><a class="footer-item" title="文档" target="_blank" rel="noopener" href="https://docs.anheyu.com/">文档</a><a class="footer-item" title="源码" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu">源码</a><a class="footer-item" title="更新日志" target="_blank" rel="noopener" href="https://blog.anheyu.com/update/">更新日志</a></div></div><div class="footer-group"><div class="footer-title">导航</div><div class="footer-links"><a class="footer-item" title="即刻短文" href="/essay">即刻短文</a><a class="footer-item" title="友链文章" href="/fcircle">友链文章</a><a class="footer-item" title="留言板" href="/comments">留言板</a></div></div><div class="footer-group"><div class="footer-title">协议</div><div class="footer-links"><a class="footer-item" title="隐私协议" href="/privacy">隐私协议</a><a class="footer-item" title="Cookies" href="/cookies">Cookies</a><a class="footer-item" title="版权协议" href="/copyright">版权协议</a></div></div><div class="footer-group"><div class="footer-title-group"><div class="footer-title">友链</div><a class="random-friends-btn" id="footer-random-friends-btn" href="javascript:addFriendLinksInFooter();" title="换一批友情链接"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right"></i></a></div><div class="footer-links" id="friend-links-in-footer"></div></div></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo 7.0.0" title="博客框架为Hexo 7.0.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/label/frame-hexo.svg" alt="博客框架为Hexo 7.0.0"/></a><a class="github-badge" target="_blank" href="https://blog.anheyu.com/" style="margin-inline:5px" data-title="本站使用AnZhiYu主题" title="本站使用AnZhiYu主题"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/label/theme-anzhiyu.svg" alt="本站使用AnZhiYu主题"/></a><a class="github-badge" target="_blank" href="https://console.upyun.com/register/?invite=nVONH00RJ" style="margin-inline:5px" data-title="本网站由又拍云提供CDN加速/云储存服务" title="本网站由又拍云提供CDN加速/云储存服务"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/label/upyun.svg" alt="本网站由又拍云提供CDN加速/云储存服务"/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/label/copyright-by-nc-sa.svg" alt="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"/></a></p></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2023 - 2024 By <a class="footer-bar-link" href="/" title="Karl" target="_blank">Karl</a></div></div><div id="footer-type-tips"></div><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#footer-type-tips", {
      strings: ["不积跬步无以至千里","今日事，今日毕","有善始者实繁，能克终者盖寡","穷且益坚，不坠青云之志","若无闲事挂心头，便是人间好时节"],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("footer-type-tips").innerHTML = '不积跬步无以至千里'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.cbd.int/typed.js@2.0.15/dist/typed.umd.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a><a class="footer-bar-link" target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" title="湘ICP备2023018619号-1">湘ICP备2023018619号-1</a><a class="footer-bar-link cc" href="/copyright" title="cc协议"><i class="anzhiyufont anzhiyu-icon-copyright-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-by-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-nc-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-nd-line"></i></a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">130</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">16</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" href="https://blog.karltan.com/" title="Karl的博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/logo.png" alt="Karl的博客"/><span class="back-menu-item-text">Karl的博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://www.karltan.com/" title="Karl的导航"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://www.karltan.com/favicon.ico" alt="Karl的导航"/><span class="back-menu-item-text">Karl的导航</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">博客分流</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://v.karltan.com/" title="Vercel"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://assets.vercel.com/image/upload/front/favicon/vercel/favicon.ico" alt="Vercel"/><span class="back-menu-item-text">Vercel</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://c.karltan.com/" title="Cloudflare"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://dash.cloudflare.com/favicon-32x32.png" alt="Cloudflare"/><span class="back-menu-item-text">Cloudflare</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">工具</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://npmzjk.karltan.com/" title="NPM"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npmzjk.karltan.com/images/favicons/favicon-32x32.png" alt="NPM"/><span class="back-menu-item-text">NPM</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://paste.karltan.com/" title="Free-Bin"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://paste.karltan.com/static/favicon.ico" alt="Free-Bin"/><span class="back-menu-item-text">Free-Bin</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://tools.karltan.com/" title="IT-TOOLS"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://tools.karltan.com/android-chrome-192x192.png" alt="IT-TOOLS"/><span class="back-menu-item-text">IT-TOOLS</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://memos.karltan.com/" title="Memos"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://memos.karltan.com/logo.png" alt="Memos"/><span class="back-menu-item-text">Memos</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://wbo.karltan.com/" title="WBO"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://wbo.karltan.com/favicon.ico" alt="WBO"/><span class="back-menu-item-text">WBO</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://git.karltan.com/" title="Gitea"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://git.karltan.com/assets/img/logo.svg" alt="Gitea"/><span class="back-menu-item-text">Gitea</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives"><i class="fa-solid fa-box-archive faa-tada"></i><span> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories"><i class="fa-solid fa-palette faa-tada"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags"><i class="fa-solid fa-tags faa-tada"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link"><i class="fa-solid fa-link faa-tada"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle"><i class="fa-brands fa-artstation faa-tada"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments"><i class="fa-solid fa-comments faa-tada"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/essay"><i class="fa-solid fa-comment-dots faa-tada"></i><span> 说说</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/music"><i class="fa-solid fa-music faa-tada"></i><span> 音乐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album"><i class="fa-solid fa-images faa-tada"></i><span> 相册</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://status.karltan.com/status/1"><i class="fa-solid fa-chart-line faa-tada"></i><span> 网站监控</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="fa-solid fa-shoe-prints faa-tada"></i><span> 随便逛逛</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/about"><i class="fa-solid fa-heart faa-tada"></i><span> 关于我</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/AcWing/" style="font-size: 0.88rem; color: rgb(85, 23, 91);">AcWing<sup>33</sup></a><a href="/tags/CUDA/" style="font-size: 0.88rem; color: rgb(12, 161, 160);">CUDA<sup>1</sup></a><a href="/tags/CVPR/" style="font-size: 0.88rem; color: rgb(147, 94, 197);">CVPR<sup>3</sup></a><a href="/tags/ICLR/" style="font-size: 0.88rem; color: rgb(43, 82, 180);">ICLR<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 0.88rem; color: rgb(122, 113, 29);">Linux<sup>1</sup></a><a href="/tags/MAPL/" style="font-size: 0.88rem; color: rgb(36, 174, 170);">MAPL<sup>1</sup></a><a href="/tags/MySQL/" style="font-size: 0.88rem; color: rgb(181, 7, 113);">MySQL<sup>1</sup></a><a href="/tags/NIPS/" style="font-size: 0.88rem; color: rgb(7, 27, 3);">NIPS<sup>1</sup></a><a href="/tags/PyTorch/" style="font-size: 0.88rem; color: rgb(150, 37, 10);">PyTorch<sup>1</sup></a><a href="/tags/Python/" style="font-size: 0.88rem; color: rgb(141, 141, 197);">Python<sup>1</sup></a><a href="/tags/RSS/" style="font-size: 0.88rem; color: rgb(112, 22, 153);">RSS<sup>1</sup></a><a href="/tags/Ubuntu/" style="font-size: 0.88rem; color: rgb(19, 93, 120);">Ubuntu<sup>3</sup></a><a href="/tags/Windows/" style="font-size: 0.88rem; color: rgb(164, 101, 25);">Windows<sup>1</sup></a><a href="/tags/arXiv/" style="font-size: 0.88rem; color: rgb(9, 118, 154);">arXiv<sup>1</sup></a><a href="/tags/mAP/" style="font-size: 0.88rem; color: rgb(199, 124, 62);">mAP<sup>1</sup></a><a href="/tags/tmux/" style="font-size: 0.88rem; color: rgb(13, 185, 37);">tmux<sup>1</sup></a><a href="/tags/vim/" style="font-size: 0.88rem; color: rgb(4, 144, 16);">vim<sup>1</sup></a><a href="/tags/%E4%BB%A3%E7%A0%81/" style="font-size: 0.88rem; color: rgb(151, 15, 28);">代码<sup>1</sup></a><a href="/tags/%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1/" style="font-size: 0.88rem; color: rgb(130, 27, 45);">位姿估计<sup>1</sup></a><a href="/tags/%E6%89%A9%E5%AE%B9/" style="font-size: 0.88rem; color: rgb(110, 175, 30);">扩容<sup>1</sup></a><a href="/tags/%E6%95%B0%E5%AD%A6/" style="font-size: 0.88rem; color: rgb(158, 42, 1);">数学<sup>1</sup></a><a href="/tags/%E6%97%8B%E8%BD%AC%E8%A1%A8%E7%A4%BA/" style="font-size: 0.88rem; color: rgb(11, 137, 41);">旋转表示<sup>1</sup></a><a href="/tags/%E6%9D%8E%E6%B2%90/" style="font-size: 0.88rem; color: rgb(109, 78, 54);">李沐<sup>76</sup></a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 0.88rem; color: rgb(99, 94, 68);">深度学习<sup>79</sup></a><a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 0.88rem; color: rgb(141, 161, 139);">目标检测<sup>1</sup></a><a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 0.88rem; color: rgb(57, 29, 124);">笔记<sup>77</sup></a><a href="/tags/%E7%AE%97%E6%B3%95%E9%A2%98/" style="font-size: 0.88rem; color: rgb(153, 5, 199);">算法题<sup>33</sup></a><a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" style="font-size: 0.88rem; color: rgb(186, 192, 126);">论文笔记<sup>9</sup></a><a href="/tags/%E9%98%BF%E9%87%8C%E4%BA%91/" style="font-size: 0.88rem; color: rgb(159, 79, 86);">阿里云<sup>1</sup></a><a href="/tags/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/" style="font-size: 0.88rem; color: rgb(7, 133, 128);">高等数学<sup>1</sup></a><a href="/tags/%E9%AD%94%E6%B3%95/" style="font-size: 0.88rem; color: rgb(99, 91, 1);">魔法<sup>1</sup></a></div></div><hr/></div></div><div id="keyboard-tips"><div class="keyboardTitle">博客快捷键</div><div class="keybordList"><div class="keybordItem"><div class="keyGroup"><div class="key">shift K</div></div><div class="keyContent"><div class="content">关闭快捷键功能</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift A</div></div><div class="keyContent"><div class="content">打开/关闭中控台</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift M</div></div><div class="keyContent"><div class="content">播放/暂停音乐</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift D</div></div><div class="keyContent"><div class="content">深色/浅色显示模式</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift S</div></div><div class="keyContent"><div class="content">站内搜索</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift R</div></div><div class="keyContent"><div class="content">随机访问</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift H</div></div><div class="keyContent"><div class="content">返回首页</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift F</div></div><div class="keyContent"><div class="content">友链鱼塘</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift L</div></div><div class="keyContent"><div class="content">友链页面</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift P</div></div><div class="keyContent"><div class="content">关于本站</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift I</div></div><div class="keyContent"><div class="content">原版/本站右键菜单</div></div></div></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="chat-btn" type="button" title="聊天"><i class="anzhiyufont anzhiyu-icon-comment-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><a id="switch-commentBarrage" href="javascript:anzhiyu.switchCommentBarrage();" title="开关弹幕"><i class="anzhiyufont anzhiyu-icon-danmu"></i></a><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.20/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.4/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script async src="/anzhiyu/random.js"></script><script async="async">(function () {
  var grt = new Date("07/15/2023 00:00:00"); //设置网站上线时间
  var now = new Date();
  var dnum;
  var hnum;
  var mnum;
  var snum;
  var nowHour;

  // 计算并更新天数、小时数、分钟数和秒数
  function updateTime() {
    now = new Date(); // 更新 now 的值
    nowHour = now.getHours(); // 更新 nowHour 的值
    var days = (now - grt) / 1000 / 60 / 60 / 24;
    dnum = Math.floor(days);
    var hours = (now - grt) / 1000 / 60 / 60 - 24 * dnum;
    hnum = Math.floor(hours);
    if (String(hnum).length == 1) {
      hnum = "0" + hnum;
    }
    var minutes = (now - grt) / 1000 / 60 - 24 * 60 * dnum - 60 * hnum;
    mnum = Math.floor(minutes);
    if (String(mnum).length == 1) {
      mnum = "0" + mnum;
    }
    var seconds = (now - grt) / 1000 - 24 * 60 * 60 * dnum - 60 * 60 * hnum - 60 * mnum;
    snum = Math.round(seconds);
    if (String(snum).length == 1) {
      snum = "0" + snum;
    }
  }

  // 更新网页中显示的网站运行时间
  function updateHtml() {
    const footer = document.getElementById("footer");
    if (!footer) return
    let currentTimeHtml = "";
    if (nowHour < 18 && nowHour >= 9) {
      // 如果是上班时间，默认就是"安知鱼-上班摸鱼中.svg"图片，不需要更改
      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    } else {
      // 如果是下班时间，插入"安知鱼-下班啦.svg"图片
      let img = document.querySelector("#workboard .workSituationImg");
      if (img != null) {
        img.src = "/img/label/offduty_img.svg";
        img.title = "延毕就延毕，我先玩了再说🤡";
        img.alt = "延毕就延毕，我先玩了再说🤡";
      }

      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    }

    if (document.getElementById("runtimeTextTip")) {
      document.getElementById("runtimeTextTip").innerHTML = currentTimeHtml;
    }
  }

  setInterval(() => {
    updateTime();
    updateHtml();
  }, 1000);
})();</script><script src="https://cdn.cbd.int/algoliasearch@4.18.0/dist/algoliasearch-lite.umd.js"></script><script src="https://cdn.cbd.int/instantsearch.js@4.56.5/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.cbd.int/mathjax@3.2.2/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.cbd.int/mermaid@10.2.4/dist/mermaid.min.js').then(runMermaid)
  }

  anzhiyu.addGlobalFn('themeChange', runMermaid, 'mermaid')

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.karltan.com/.netlify/functions/twikoo',
      region: '',
      onCommentLoaded: () => {
        anzhiyu.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(runFn,0)
    else getScript('https://cdn.cbd.int/twikoo@1.6.25/dist/twikoo.all.min.js').then(runFn)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.karltan.com/.netlify/functions/twikoo',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const runFn = () => {
    init();
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"><script async src="/js/anzhiyu/comment_barrage.js"></script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://twikoo.karltan.com/.netlify/functions/twikoo',
        region: '',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.cbd.int/twikoo@1.6.25/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'><div class='name'><span>${array[i].nick} </span></div></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "visitor@karltan.com";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script src="/js/anzhiyu/right_click_menu.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><script>window.va = window.va || function () { (window.vaq = window.vaq || []).push(arguments); };</script><script defer src="/_vercel/insights/script.js"></script><script charset="UTF-8" id="LA_COLLECT" src="https://sdk.51.la/js-sdk-pro.min.js"></script><script src="https://sdk.51.la/perf/js-sdk-perf.min.js" crossorigin="anonymous"></script><script>LA.init({id:"{3GbfAYtZPDEan7kS}",ck:"{3Gbf0O9t4EtAOhf1}"})</script><script>new LingQue.Monitor().init({id:"3GbfAYtZPDEan7kS",sendSuspicious:true});</script><script>(() => {
  window.$crisp = [];
  window.CRISP_WEBSITE_ID = "99975f47-0cf6-4a4b-8088-49fd5cb33ab0";
  (function () {
    d = document;
    s = d.createElement("script");
    s.src = "https://client.crisp.chat/l.js";
    s.async = 1;
    d.getElementsByTagName("head")[0].appendChild(s);
  })();
  $crisp.push(["safe", true])

  const isChatBtn = true
  const isChatHideShow = false

  if (isChatBtn) {
    const open = () => {
      $crisp.push(["do", "chat:show"])
      $crisp.push(["do", "chat:open"])
    }

    const close = () => {
      $crisp.push(["do", "chat:hide"])
    }

    close()
    $crisp.push(["on", "chat:closed", function() {
      close()
    }])

    window.chatBtnFn = () => {
      $crisp.is("chat:visible") ? close() : open()
    }
  } else if (isChatHideShow) {
    window.chatBtn = {
      hide: () => {
        $crisp.push(["do", "chat:hide"])
      },
      show: () => {
        $crisp.push(["do", "chat:show"])
      }
    }
  }
})()</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","meta[property=\"og:type\"]","meta[property=\"og:site_name\"]","meta[property=\"og:description\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>